# Daily Papers
The project automatically fetches the latest papers from arXiv based on keywords.

The subheadings in the README file represent the search keywords.

Only the most recent articles for each keyword are retained, up to a maximum of 100 papers.

You can click the 'Watch' button to receive daily email notifications.

Last update: 2026-01-07

## Molecular
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[Question Answering for Multi-Release Systems: A Case Study at Ciena](https://arxiv.org/abs/2601.02345v1)** | 2026-01-05 | <details><summary>Show</summary><p>Companies regularly have to contend with multi-release systems, where several versions of the same software are in operation simultaneously. Question answering over documents from multi-release systems poses challenges because different releases have distinct yet overlapping documentation. Motivated by the observed inaccuracy of state-of-the-art question-answering techniques on multi-release system documents, we propose QAMR, a chatbot designed to answer questions across multi-release system documentation. QAMR enhances traditional retrieval-augmented generation (RAG) to ensure accuracy in the face of highly similar yet distinct documentation for different releases. It achieves this through a novel combination of pre-processing, query rewriting, and context selection. In addition, QAMR employs a dual-chunking strategy to enable separately tuned chunk sizes for retrieval and answer generation, improving overall question-answering accuracy. We evaluate QAMR using a public software-engineering benchmark as well as a collection of real-world, multi-release system documents from our industry partner, Ciena. Our evaluation yields five main findings: (1) QAMR outperforms a baseline RAG-based chatbot, achieving an average answer correctness of 88.5% and an average retrieval accuracy of 90%, which correspond to improvements of 16.5% and 12%, respectively. (2) An ablation study shows that QAMR's mechanisms for handling multi-release documents directly improve answer accuracy. (3) Compared to its component-ablated variants, QAMR achieves a 19.6% average gain in answer correctness and a 14.0% average gain in retrieval accuracy over the best ablation. (4) QAMR reduces response time by 8% on average relative to the baseline. (5) The automatically computed accuracy metrics used in our evaluation strongly correlate with expert human assessments, validating the reliability of our methodology.</p></details> | <details><summary>Accep...</summary><p>Accepted for publication in SANER 2026</p></details> |
| **[Fusion2Print: Deep Flash-Non-Flash Fusion for Contactless Fingerprint Matching](https://arxiv.org/abs/2601.02318v1)** | 2026-01-05 | <details><summary>Show</summary><p>Contactless fingerprint recognition offers a hygienic and convenient alternative to contact-based systems, enabling rapid acquisition without latent prints, pressure artifacts, or hygiene risks. However, contactless images often show degraded ridge clarity due to illumination variation, subcutaneous skin discoloration, and specular reflections. Flash captures preserve ridge detail but introduce noise, whereas non-flash captures reduce noise but lower ridge contrast. We propose Fusion2Print (F2P), the first framework to systematically capture and fuse paired flash-non-flash contactless fingerprints. We construct a custom paired dataset, FNF Database, and perform manual flash-non-flash subtraction to isolate ridge-preserving signals. A lightweight attention-based fusion network also integrates both modalities, emphasizing informative channels and suppressing noise, and then a U-Net enhancement module produces an optimally weighted grayscale image. Finally, a deep embedding model with cross-domain compatibility, generates discriminative and robust representations in a unified embedding space compatible with both contactless and contact-based fingerprints for verification. F2P enhances ridge clarity and achieves superior recognition performance (AUC=0.999, EER=1.12%) over single-capture baselines (Verifinger, DeepPrint).</p></details> | <details><summary>15 pa...</summary><p>15 pages, 8 figures, 5 tables. Submitted to ICPR 2026</p></details> |
| **[Tales of the 2025 Los Angeles Fire: Hotwash for Public Health Concerns in Reddit via LLM-Enhanced Topic Modeling](https://arxiv.org/abs/2505.09665v3)** | 2026-01-05 | <details><summary>Show</summary><p>Wildfires have become increasingly frequent, irregular, and severe in recent years. Understanding how affected populations perceive and respond during wildfire crises is critical for timely and empathetic disaster response. Social media platforms offer a crowd-sourced channel to capture evolving public discourse, providing hyperlocal information and insight into public sentiment. This study analyzes Reddit discourse during the 2025 Los Angeles wildfires, spanning from the onset of the disaster to full containment. We collect 385 posts and 114,879 comments related to the Palisades and Eaton fires. We adopt topic modeling methods to identify the latent topics, enhanced by large language models (LLMs) and human-in-the-loop (HITL) refinement. Furthermore, we develop a hierarchical framework to categorize latent topics, consisting of two main categories, Situational Awareness (SA) and Crisis Narratives (CN). The volume of SA category closely aligns with real-world fire progressions, peaking within the first 2-5 days as the fires reach the maximum extent. The most frequent co-occurring category set of public health and safety, loss and damage, and emergency resources expands on a wide range of health-related latent topics, including environmental health, occupational health, and one health. Grief signals and mental health risks consistently accounted for 60 percentage and 40 percentage of CN instances, respectively, with the highest total volume occurring at night. This study contributes the first annotated social media dataset on the 2025 LA fires, and introduces a scalable multi-layer framework that leverages topic modeling for crisis discourse analysis. By identifying persistent public health concerns, our results can inform more empathetic and adaptive strategies for disaster response, public health communication, and future research in comparable climate-related disaster events.</p></details> | <details><summary>Fix t...</summary><p>Fix typos in Method Section. Add data/code availability</p></details> |
| **[Temporal Kolmogorov-Arnold Networks (T-KAN) for High-Frequency Limit Order Book Forecasting: Efficiency, Interpretability, and Alpha Decay](https://arxiv.org/abs/2601.02310v1)** | 2026-01-05 | <details><summary>Show</summary><p>High-Frequency trading (HFT) environments are characterised by large volumes of limit order book (LOB) data, which is notoriously noisy and non-linear. Alpha decay represents a significant challenge, with traditional models such as DeepLOB losing predictive power as the time horizon (k) increases. In this paper, using data from the FI-2010 dataset, we introduce Temporal Kolmogorov-Arnold Networks (T-KAN) to replace the fixed, linear weights of standard LSTMs with learnable B-spline activation functions. This allows the model to learn the 'shape' of market signals as opposed to just their magnitude. This resulted in a 19.1% relative improvement in the F1-score at the k = 100 horizon. The efficacy of T-KAN networks cannot be understated, producing a 132.48% return compared to the -82.76% DeepLOB drawdown under 1.0 bps transaction costs. In addition to this, the T-KAN model proves quite interpretable, with the 'dead-zones' being clearly visible in the splines. The T-KAN architecture is also uniquely optimized for low-latency FPGA implementation via High level Synthesis (HLS). The code for the experiments in this project can be found at https://github.com/AhmadMak/Temporal-Kolmogorov-Arnold-Networks-T-KAN-for-High-Frequency-Limit-Order-Book-Forecasting.</p></details> | <details><summary>8 pag...</summary><p>8 pages, 5 figures, Proposes T-KAN architecture for HFT. Achieves 19.1% F1-score improvement on FI-2010 and 132.48% return in cost-adjusted backtests.Proposes T-KAN architecture for HFT. Achieves 19.1% F1-score improvement on FI-2010 and 132.48% return in cost-adjusted backtests</p></details> |
| **[Classifying several dialectal Nawatl varieties](https://arxiv.org/abs/2601.02303v1)** | 2026-01-05 | <details><summary>Show</summary><p>Mexico is a country with a large number of indigenous languages, among which the most widely spoken is Nawatl, with more than two million people currently speaking it (mainly in North and Central America). Despite its rich cultural heritage, which dates back to the 15th century, Nawatl is a language with few computer resources. The problem is compounded when it comes to its dialectal varieties, with approximately 30 varieties recognised, not counting the different spellings in the written forms of the language. In this research work, we addressed the problem of classifying Nawatl varieties using Machine Learning and Neural Networks.</p></details> | <details><summary>9 pag...</summary><p>9 pages, 5 figures, 4 tables</p></details> |
| **[Generative Site-Specific Beamforming for Next-Generation Spatial Intelligence](https://arxiv.org/abs/2601.02301v1)** | 2026-01-05 | <details><summary>Show</summary><p>This article proposes generative site-specific beamforming (GenSSBF) for next-generation spatial intelligence in wireless networks. Site-specific beamforming (SSBF) has emerged as a promising paradigm to mitigate the channel acquisition bottleneck in multiantenna systems by exploiting environmental priors. However, classical SSBF based on discriminative deep learning struggles: 1) to properly represent the inherent multimodality of wireless propagation and 2) to effectively capture the structural features of beamformers. In contrast, by leveraging conditional generative models, GenSSBF addresses these issues via learning a conditional distribution over feasible beamformers. By doing so, the synthesis of diverse and high-fidelity beam candidates from coarse channel sensing measurements can be guaranteed. This article presents the fundamentals, system designs, and implementation methods of GenSSBF. Case studies in both indoor and outdoor scenarios show that GenSSBF attains near-optimal beamforming gain with ultra-low channel acquisition overhead. Finally, several open research problems are highlighted.</p></details> | 7 pages, 5 figures |
| **[An Automatic Pipeline for the Integration of Python-Based Tools into the Galaxy Platform: Application to the anvi'o Framework](https://arxiv.org/abs/2601.02283v1)** | 2026-01-05 | <details><summary>Show</summary><p>The integration of command-line tools into the Galaxy platform is crucial for making complex computational methods accessible to a broader audience and ensuring reproducible research. However, the manual development of tool wrappers is a time-consuming, error-prone, and knowledge-intensive process. This bottleneck significantly affects the rapid deployment of new and updated tools, creating a gap between tool development and its availability to the scientific community. We have developed a novel, automated approach that directly translates Python tool interfaces into Galaxy-compliant tool wrappers. Our method leverages the argparse library, a standard for command-line argument parsing in Python. By embedding structured metadata within the metavar attribute of input and output arguments, our system programmatically parses the tool's interface to extract all necessary information. This includes parameter types, data formats, help text, and input/output definitions. The system then uses this information to automatically generate a complete and valid Galaxy tool XML wrapper, requiring no manual intervention. To validate the scalability and effectiveness of our approach, we applied it to the anvi'o framework, a comprehensive and complex bioinformatics platform comprising hundreds of individual programs. Our method successfully parsed the argparse definitions for the entire anvi'o suite and generated functional Galaxy tool wrappers. The resulting integration allows for the seamless execution of anvi'o workflows within the Galaxy environment. This work presents a significant advancement in the automation of tool integration for scientific workflow systems. By establishing a convention-based approach using Python's argparse library, we have created a scalable and generalizable solution that dramatically reduces the effort required to make command-line tools available in Galaxy.</p></details> | 26 pages, 5 figures |

## Molecular Generation
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[Question Answering for Multi-Release Systems: A Case Study at Ciena](https://arxiv.org/abs/2601.02345v1)** | 2026-01-05 | <details><summary>Show</summary><p>Companies regularly have to contend with multi-release systems, where several versions of the same software are in operation simultaneously. Question answering over documents from multi-release systems poses challenges because different releases have distinct yet overlapping documentation. Motivated by the observed inaccuracy of state-of-the-art question-answering techniques on multi-release system documents, we propose QAMR, a chatbot designed to answer questions across multi-release system documentation. QAMR enhances traditional retrieval-augmented generation (RAG) to ensure accuracy in the face of highly similar yet distinct documentation for different releases. It achieves this through a novel combination of pre-processing, query rewriting, and context selection. In addition, QAMR employs a dual-chunking strategy to enable separately tuned chunk sizes for retrieval and answer generation, improving overall question-answering accuracy. We evaluate QAMR using a public software-engineering benchmark as well as a collection of real-world, multi-release system documents from our industry partner, Ciena. Our evaluation yields five main findings: (1) QAMR outperforms a baseline RAG-based chatbot, achieving an average answer correctness of 88.5% and an average retrieval accuracy of 90%, which correspond to improvements of 16.5% and 12%, respectively. (2) An ablation study shows that QAMR's mechanisms for handling multi-release documents directly improve answer accuracy. (3) Compared to its component-ablated variants, QAMR achieves a 19.6% average gain in answer correctness and a 14.0% average gain in retrieval accuracy over the best ablation. (4) QAMR reduces response time by 8% on average relative to the baseline. (5) The automatically computed accuracy metrics used in our evaluation strongly correlate with expert human assessments, validating the reliability of our methodology.</p></details> | <details><summary>Accep...</summary><p>Accepted for publication in SANER 2026</p></details> |
| **[Fusion2Print: Deep Flash-Non-Flash Fusion for Contactless Fingerprint Matching](https://arxiv.org/abs/2601.02318v1)** | 2026-01-05 | <details><summary>Show</summary><p>Contactless fingerprint recognition offers a hygienic and convenient alternative to contact-based systems, enabling rapid acquisition without latent prints, pressure artifacts, or hygiene risks. However, contactless images often show degraded ridge clarity due to illumination variation, subcutaneous skin discoloration, and specular reflections. Flash captures preserve ridge detail but introduce noise, whereas non-flash captures reduce noise but lower ridge contrast. We propose Fusion2Print (F2P), the first framework to systematically capture and fuse paired flash-non-flash contactless fingerprints. We construct a custom paired dataset, FNF Database, and perform manual flash-non-flash subtraction to isolate ridge-preserving signals. A lightweight attention-based fusion network also integrates both modalities, emphasizing informative channels and suppressing noise, and then a U-Net enhancement module produces an optimally weighted grayscale image. Finally, a deep embedding model with cross-domain compatibility, generates discriminative and robust representations in a unified embedding space compatible with both contactless and contact-based fingerprints for verification. F2P enhances ridge clarity and achieves superior recognition performance (AUC=0.999, EER=1.12%) over single-capture baselines (Verifinger, DeepPrint).</p></details> | <details><summary>15 pa...</summary><p>15 pages, 8 figures, 5 tables. Submitted to ICPR 2026</p></details> |
| **[Tales of the 2025 Los Angeles Fire: Hotwash for Public Health Concerns in Reddit via LLM-Enhanced Topic Modeling](https://arxiv.org/abs/2505.09665v3)** | 2026-01-05 | <details><summary>Show</summary><p>Wildfires have become increasingly frequent, irregular, and severe in recent years. Understanding how affected populations perceive and respond during wildfire crises is critical for timely and empathetic disaster response. Social media platforms offer a crowd-sourced channel to capture evolving public discourse, providing hyperlocal information and insight into public sentiment. This study analyzes Reddit discourse during the 2025 Los Angeles wildfires, spanning from the onset of the disaster to full containment. We collect 385 posts and 114,879 comments related to the Palisades and Eaton fires. We adopt topic modeling methods to identify the latent topics, enhanced by large language models (LLMs) and human-in-the-loop (HITL) refinement. Furthermore, we develop a hierarchical framework to categorize latent topics, consisting of two main categories, Situational Awareness (SA) and Crisis Narratives (CN). The volume of SA category closely aligns with real-world fire progressions, peaking within the first 2-5 days as the fires reach the maximum extent. The most frequent co-occurring category set of public health and safety, loss and damage, and emergency resources expands on a wide range of health-related latent topics, including environmental health, occupational health, and one health. Grief signals and mental health risks consistently accounted for 60 percentage and 40 percentage of CN instances, respectively, with the highest total volume occurring at night. This study contributes the first annotated social media dataset on the 2025 LA fires, and introduces a scalable multi-layer framework that leverages topic modeling for crisis discourse analysis. By identifying persistent public health concerns, our results can inform more empathetic and adaptive strategies for disaster response, public health communication, and future research in comparable climate-related disaster events.</p></details> | <details><summary>Fix t...</summary><p>Fix typos in Method Section. Add data/code availability</p></details> |
| **[Temporal Kolmogorov-Arnold Networks (T-KAN) for High-Frequency Limit Order Book Forecasting: Efficiency, Interpretability, and Alpha Decay](https://arxiv.org/abs/2601.02310v1)** | 2026-01-05 | <details><summary>Show</summary><p>High-Frequency trading (HFT) environments are characterised by large volumes of limit order book (LOB) data, which is notoriously noisy and non-linear. Alpha decay represents a significant challenge, with traditional models such as DeepLOB losing predictive power as the time horizon (k) increases. In this paper, using data from the FI-2010 dataset, we introduce Temporal Kolmogorov-Arnold Networks (T-KAN) to replace the fixed, linear weights of standard LSTMs with learnable B-spline activation functions. This allows the model to learn the 'shape' of market signals as opposed to just their magnitude. This resulted in a 19.1% relative improvement in the F1-score at the k = 100 horizon. The efficacy of T-KAN networks cannot be understated, producing a 132.48% return compared to the -82.76% DeepLOB drawdown under 1.0 bps transaction costs. In addition to this, the T-KAN model proves quite interpretable, with the 'dead-zones' being clearly visible in the splines. The T-KAN architecture is also uniquely optimized for low-latency FPGA implementation via High level Synthesis (HLS). The code for the experiments in this project can be found at https://github.com/AhmadMak/Temporal-Kolmogorov-Arnold-Networks-T-KAN-for-High-Frequency-Limit-Order-Book-Forecasting.</p></details> | <details><summary>8 pag...</summary><p>8 pages, 5 figures, Proposes T-KAN architecture for HFT. Achieves 19.1% F1-score improvement on FI-2010 and 132.48% return in cost-adjusted backtests.Proposes T-KAN architecture for HFT. Achieves 19.1% F1-score improvement on FI-2010 and 132.48% return in cost-adjusted backtests</p></details> |
| **[Classifying several dialectal Nawatl varieties](https://arxiv.org/abs/2601.02303v1)** | 2026-01-05 | <details><summary>Show</summary><p>Mexico is a country with a large number of indigenous languages, among which the most widely spoken is Nawatl, with more than two million people currently speaking it (mainly in North and Central America). Despite its rich cultural heritage, which dates back to the 15th century, Nawatl is a language with few computer resources. The problem is compounded when it comes to its dialectal varieties, with approximately 30 varieties recognised, not counting the different spellings in the written forms of the language. In this research work, we addressed the problem of classifying Nawatl varieties using Machine Learning and Neural Networks.</p></details> | <details><summary>9 pag...</summary><p>9 pages, 5 figures, 4 tables</p></details> |
| **[Generative Site-Specific Beamforming for Next-Generation Spatial Intelligence](https://arxiv.org/abs/2601.02301v1)** | 2026-01-05 | <details><summary>Show</summary><p>This article proposes generative site-specific beamforming (GenSSBF) for next-generation spatial intelligence in wireless networks. Site-specific beamforming (SSBF) has emerged as a promising paradigm to mitigate the channel acquisition bottleneck in multiantenna systems by exploiting environmental priors. However, classical SSBF based on discriminative deep learning struggles: 1) to properly represent the inherent multimodality of wireless propagation and 2) to effectively capture the structural features of beamformers. In contrast, by leveraging conditional generative models, GenSSBF addresses these issues via learning a conditional distribution over feasible beamformers. By doing so, the synthesis of diverse and high-fidelity beam candidates from coarse channel sensing measurements can be guaranteed. This article presents the fundamentals, system designs, and implementation methods of GenSSBF. Case studies in both indoor and outdoor scenarios show that GenSSBF attains near-optimal beamforming gain with ultra-low channel acquisition overhead. Finally, several open research problems are highlighted.</p></details> | 7 pages, 5 figures |
| **[An Automatic Pipeline for the Integration of Python-Based Tools into the Galaxy Platform: Application to the anvi'o Framework](https://arxiv.org/abs/2601.02283v1)** | 2026-01-05 | <details><summary>Show</summary><p>The integration of command-line tools into the Galaxy platform is crucial for making complex computational methods accessible to a broader audience and ensuring reproducible research. However, the manual development of tool wrappers is a time-consuming, error-prone, and knowledge-intensive process. This bottleneck significantly affects the rapid deployment of new and updated tools, creating a gap between tool development and its availability to the scientific community. We have developed a novel, automated approach that directly translates Python tool interfaces into Galaxy-compliant tool wrappers. Our method leverages the argparse library, a standard for command-line argument parsing in Python. By embedding structured metadata within the metavar attribute of input and output arguments, our system programmatically parses the tool's interface to extract all necessary information. This includes parameter types, data formats, help text, and input/output definitions. The system then uses this information to automatically generate a complete and valid Galaxy tool XML wrapper, requiring no manual intervention. To validate the scalability and effectiveness of our approach, we applied it to the anvi'o framework, a comprehensive and complex bioinformatics platform comprising hundreds of individual programs. Our method successfully parsed the argparse definitions for the entire anvi'o suite and generated functional Galaxy tool wrappers. The resulting integration allows for the seamless execution of anvi'o workflows within the Galaxy environment. This work presents a significant advancement in the automation of tool integration for scientific workflow systems. By establishing a convention-based approach using Python's argparse library, we have created a scalable and generalizable solution that dramatically reduces the effort required to make command-line tools available in Galaxy.</p></details> | 26 pages, 5 figures |

## Graph Neural Networks
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[Question Answering for Multi-Release Systems: A Case Study at Ciena](https://arxiv.org/abs/2601.02345v1)** | 2026-01-05 | <details><summary>Show</summary><p>Companies regularly have to contend with multi-release systems, where several versions of the same software are in operation simultaneously. Question answering over documents from multi-release systems poses challenges because different releases have distinct yet overlapping documentation. Motivated by the observed inaccuracy of state-of-the-art question-answering techniques on multi-release system documents, we propose QAMR, a chatbot designed to answer questions across multi-release system documentation. QAMR enhances traditional retrieval-augmented generation (RAG) to ensure accuracy in the face of highly similar yet distinct documentation for different releases. It achieves this through a novel combination of pre-processing, query rewriting, and context selection. In addition, QAMR employs a dual-chunking strategy to enable separately tuned chunk sizes for retrieval and answer generation, improving overall question-answering accuracy. We evaluate QAMR using a public software-engineering benchmark as well as a collection of real-world, multi-release system documents from our industry partner, Ciena. Our evaluation yields five main findings: (1) QAMR outperforms a baseline RAG-based chatbot, achieving an average answer correctness of 88.5% and an average retrieval accuracy of 90%, which correspond to improvements of 16.5% and 12%, respectively. (2) An ablation study shows that QAMR's mechanisms for handling multi-release documents directly improve answer accuracy. (3) Compared to its component-ablated variants, QAMR achieves a 19.6% average gain in answer correctness and a 14.0% average gain in retrieval accuracy over the best ablation. (4) QAMR reduces response time by 8% on average relative to the baseline. (5) The automatically computed accuracy metrics used in our evaluation strongly correlate with expert human assessments, validating the reliability of our methodology.</p></details> | <details><summary>Accep...</summary><p>Accepted for publication in SANER 2026</p></details> |
| **[Fusion2Print: Deep Flash-Non-Flash Fusion for Contactless Fingerprint Matching](https://arxiv.org/abs/2601.02318v1)** | 2026-01-05 | <details><summary>Show</summary><p>Contactless fingerprint recognition offers a hygienic and convenient alternative to contact-based systems, enabling rapid acquisition without latent prints, pressure artifacts, or hygiene risks. However, contactless images often show degraded ridge clarity due to illumination variation, subcutaneous skin discoloration, and specular reflections. Flash captures preserve ridge detail but introduce noise, whereas non-flash captures reduce noise but lower ridge contrast. We propose Fusion2Print (F2P), the first framework to systematically capture and fuse paired flash-non-flash contactless fingerprints. We construct a custom paired dataset, FNF Database, and perform manual flash-non-flash subtraction to isolate ridge-preserving signals. A lightweight attention-based fusion network also integrates both modalities, emphasizing informative channels and suppressing noise, and then a U-Net enhancement module produces an optimally weighted grayscale image. Finally, a deep embedding model with cross-domain compatibility, generates discriminative and robust representations in a unified embedding space compatible with both contactless and contact-based fingerprints for verification. F2P enhances ridge clarity and achieves superior recognition performance (AUC=0.999, EER=1.12%) over single-capture baselines (Verifinger, DeepPrint).</p></details> | <details><summary>15 pa...</summary><p>15 pages, 8 figures, 5 tables. Submitted to ICPR 2026</p></details> |
| **[Tales of the 2025 Los Angeles Fire: Hotwash for Public Health Concerns in Reddit via LLM-Enhanced Topic Modeling](https://arxiv.org/abs/2505.09665v3)** | 2026-01-05 | <details><summary>Show</summary><p>Wildfires have become increasingly frequent, irregular, and severe in recent years. Understanding how affected populations perceive and respond during wildfire crises is critical for timely and empathetic disaster response. Social media platforms offer a crowd-sourced channel to capture evolving public discourse, providing hyperlocal information and insight into public sentiment. This study analyzes Reddit discourse during the 2025 Los Angeles wildfires, spanning from the onset of the disaster to full containment. We collect 385 posts and 114,879 comments related to the Palisades and Eaton fires. We adopt topic modeling methods to identify the latent topics, enhanced by large language models (LLMs) and human-in-the-loop (HITL) refinement. Furthermore, we develop a hierarchical framework to categorize latent topics, consisting of two main categories, Situational Awareness (SA) and Crisis Narratives (CN). The volume of SA category closely aligns with real-world fire progressions, peaking within the first 2-5 days as the fires reach the maximum extent. The most frequent co-occurring category set of public health and safety, loss and damage, and emergency resources expands on a wide range of health-related latent topics, including environmental health, occupational health, and one health. Grief signals and mental health risks consistently accounted for 60 percentage and 40 percentage of CN instances, respectively, with the highest total volume occurring at night. This study contributes the first annotated social media dataset on the 2025 LA fires, and introduces a scalable multi-layer framework that leverages topic modeling for crisis discourse analysis. By identifying persistent public health concerns, our results can inform more empathetic and adaptive strategies for disaster response, public health communication, and future research in comparable climate-related disaster events.</p></details> | <details><summary>Fix t...</summary><p>Fix typos in Method Section. Add data/code availability</p></details> |
| **[Temporal Kolmogorov-Arnold Networks (T-KAN) for High-Frequency Limit Order Book Forecasting: Efficiency, Interpretability, and Alpha Decay](https://arxiv.org/abs/2601.02310v1)** | 2026-01-05 | <details><summary>Show</summary><p>High-Frequency trading (HFT) environments are characterised by large volumes of limit order book (LOB) data, which is notoriously noisy and non-linear. Alpha decay represents a significant challenge, with traditional models such as DeepLOB losing predictive power as the time horizon (k) increases. In this paper, using data from the FI-2010 dataset, we introduce Temporal Kolmogorov-Arnold Networks (T-KAN) to replace the fixed, linear weights of standard LSTMs with learnable B-spline activation functions. This allows the model to learn the 'shape' of market signals as opposed to just their magnitude. This resulted in a 19.1% relative improvement in the F1-score at the k = 100 horizon. The efficacy of T-KAN networks cannot be understated, producing a 132.48% return compared to the -82.76% DeepLOB drawdown under 1.0 bps transaction costs. In addition to this, the T-KAN model proves quite interpretable, with the 'dead-zones' being clearly visible in the splines. The T-KAN architecture is also uniquely optimized for low-latency FPGA implementation via High level Synthesis (HLS). The code for the experiments in this project can be found at https://github.com/AhmadMak/Temporal-Kolmogorov-Arnold-Networks-T-KAN-for-High-Frequency-Limit-Order-Book-Forecasting.</p></details> | <details><summary>8 pag...</summary><p>8 pages, 5 figures, Proposes T-KAN architecture for HFT. Achieves 19.1% F1-score improvement on FI-2010 and 132.48% return in cost-adjusted backtests.Proposes T-KAN architecture for HFT. Achieves 19.1% F1-score improvement on FI-2010 and 132.48% return in cost-adjusted backtests</p></details> |
| **[Classifying several dialectal Nawatl varieties](https://arxiv.org/abs/2601.02303v1)** | 2026-01-05 | <details><summary>Show</summary><p>Mexico is a country with a large number of indigenous languages, among which the most widely spoken is Nawatl, with more than two million people currently speaking it (mainly in North and Central America). Despite its rich cultural heritage, which dates back to the 15th century, Nawatl is a language with few computer resources. The problem is compounded when it comes to its dialectal varieties, with approximately 30 varieties recognised, not counting the different spellings in the written forms of the language. In this research work, we addressed the problem of classifying Nawatl varieties using Machine Learning and Neural Networks.</p></details> | <details><summary>9 pag...</summary><p>9 pages, 5 figures, 4 tables</p></details> |
| **[Generative Site-Specific Beamforming for Next-Generation Spatial Intelligence](https://arxiv.org/abs/2601.02301v1)** | 2026-01-05 | <details><summary>Show</summary><p>This article proposes generative site-specific beamforming (GenSSBF) for next-generation spatial intelligence in wireless networks. Site-specific beamforming (SSBF) has emerged as a promising paradigm to mitigate the channel acquisition bottleneck in multiantenna systems by exploiting environmental priors. However, classical SSBF based on discriminative deep learning struggles: 1) to properly represent the inherent multimodality of wireless propagation and 2) to effectively capture the structural features of beamformers. In contrast, by leveraging conditional generative models, GenSSBF addresses these issues via learning a conditional distribution over feasible beamformers. By doing so, the synthesis of diverse and high-fidelity beam candidates from coarse channel sensing measurements can be guaranteed. This article presents the fundamentals, system designs, and implementation methods of GenSSBF. Case studies in both indoor and outdoor scenarios show that GenSSBF attains near-optimal beamforming gain with ultra-low channel acquisition overhead. Finally, several open research problems are highlighted.</p></details> | 7 pages, 5 figures |
| **[An Automatic Pipeline for the Integration of Python-Based Tools into the Galaxy Platform: Application to the anvi'o Framework](https://arxiv.org/abs/2601.02283v1)** | 2026-01-05 | <details><summary>Show</summary><p>The integration of command-line tools into the Galaxy platform is crucial for making complex computational methods accessible to a broader audience and ensuring reproducible research. However, the manual development of tool wrappers is a time-consuming, error-prone, and knowledge-intensive process. This bottleneck significantly affects the rapid deployment of new and updated tools, creating a gap between tool development and its availability to the scientific community. We have developed a novel, automated approach that directly translates Python tool interfaces into Galaxy-compliant tool wrappers. Our method leverages the argparse library, a standard for command-line argument parsing in Python. By embedding structured metadata within the metavar attribute of input and output arguments, our system programmatically parses the tool's interface to extract all necessary information. This includes parameter types, data formats, help text, and input/output definitions. The system then uses this information to automatically generate a complete and valid Galaxy tool XML wrapper, requiring no manual intervention. To validate the scalability and effectiveness of our approach, we applied it to the anvi'o framework, a comprehensive and complex bioinformatics platform comprising hundreds of individual programs. Our method successfully parsed the argparse definitions for the entire anvi'o suite and generated functional Galaxy tool wrappers. The resulting integration allows for the seamless execution of anvi'o workflows within the Galaxy environment. This work presents a significant advancement in the automation of tool integration for scientific workflow systems. By establishing a convention-based approach using Python's argparse library, we have created a scalable and generalizable solution that dramatically reduces the effort required to make command-line tools available in Galaxy.</p></details> | 26 pages, 5 figures |

## Diffusion
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[ExposeAnyone: Personalized Audio-to-Expression Diffusion Models Are Robust Zero-Shot Face Forgery Detectors](https://arxiv.org/abs/2601.02359v1)** | 2026-01-05 | <details><summary>Show</summary><p>Detecting unknown deepfake manipulations remains one of the most challenging problems in face forgery detection. Current state-of-the-art approaches fail to generalize to unseen manipulations, as they primarily rely on supervised training with existing deepfakes or pseudo-fakes, which leads to overfitting to specific forgery patterns. In contrast, self-supervised methods offer greater potential for generalization, but existing work struggles to learn discriminative representations only from self-supervision. In this paper, we propose ExposeAnyone, a fully self-supervised approach based on a diffusion model that generates expression sequences from audio. The key idea is, once the model is personalized to specific subjects using reference sets, it can compute the identity distances between suspected videos and personalized subjects via diffusion reconstruction errors, enabling person-of-interest face forgery detection. Extensive experiments demonstrate that 1) our method outperforms the previous state-of-the-art method by 4.22 percentage points in the average AUC on DF-TIMIT, DFDCP, KoDF, and IDForge datasets, 2) our model is also capable of detecting Sora2-generated videos, where the previous approaches perform poorly, and 3) our method is highly robust to corruptions such as blur and compression, highlighting the applicability in real-world face forgery detection.</p></details> | <details><summary>17 pa...</summary><p>17 pages, 8 figures, 11 tables; project page: https://mapooon.github.io/ExposeAnyonePage/</p></details> |
| **[VINO: A Unified Visual Generator with Interleaved OmniModal Context](https://arxiv.org/abs/2601.02358v1)** | 2026-01-05 | <details><summary>Show</summary><p>We present VINO, a unified visual generator that performs image and video generation and editing within a single framework. Instead of relying on task-specific models or independent modules for each modality, VINO uses a shared diffusion backbone that conditions on text, images and videos, enabling a broad range of visual creation and editing tasks under one model. Specifically, VINO couples a vision-language model (VLM) with a Multimodal Diffusion Transformer (MMDiT), where multimodal inputs are encoded as interleaved conditioning tokens, and then used to guide the diffusion process. This design supports multi-reference grounding, long-form instruction following, and coherent identity preservation across static and dynamic content, while avoiding modality-specific architectural components. To train such a unified system, we introduce a multi-stage training pipeline that progressively expands a video generation base model into a unified, multi-task generator capable of both image and video input and output. Across diverse generation and editing benchmarks, VINO demonstrates strong visual quality, faithful instruction following, improved reference and attribute preservation, and more controllable multi-identity edits. Our results highlight a practical path toward scalable unified visual generation, and the promise of interleaved, in-context computation as a foundation for general-purpose visual creation.</p></details> | <details><summary>Proje...</summary><p>Project page: https://sotamak1r.github.io/VINO-web/</p></details> |
| **[Talk2Move: Reinforcement Learning for Text-Instructed Object-Level Geometric Transformation in Scenes](https://arxiv.org/abs/2601.02356v1)** | 2026-01-05 | <details><summary>Show</summary><p>We introduce Talk2Move, a reinforcement learning (RL) based diffusion framework for text-instructed spatial transformation of objects within scenes. Spatially manipulating objects in a scene through natural language poses a challenge for multimodal generation systems. While existing text-based manipulation methods can adjust appearance or style, they struggle to perform object-level geometric transformations-such as translating, rotating, or resizing objects-due to scarce paired supervision and pixel-level optimization limits. Talk2Move employs Group Relative Policy Optimization (GRPO) to explore geometric actions through diverse rollouts generated from input images and lightweight textual variations, removing the need for costly paired data. A spatial reward guided model aligns geometric transformations with linguistic description, while off-policy step evaluation and active step sampling improve learning efficiency by focusing on informative transformation stages. Furthermore, we design object-centric spatial rewards that evaluate displacement, rotation, and scaling behaviors directly, enabling interpretable and coherent transformations. Experiments on curated benchmarks demonstrate that Talk2Move achieves precise, consistent, and semantically faithful object transformations, outperforming existing text-guided editing approaches in both spatial accuracy and scene coherence.</p></details> | <details><summary>Proje...</summary><p>Project page: https://sparkstj.github.io/talk2move</p></details> |
| **[Question Answering for Multi-Release Systems: A Case Study at Ciena](https://arxiv.org/abs/2601.02345v1)** | 2026-01-05 | <details><summary>Show</summary><p>Companies regularly have to contend with multi-release systems, where several versions of the same software are in operation simultaneously. Question answering over documents from multi-release systems poses challenges because different releases have distinct yet overlapping documentation. Motivated by the observed inaccuracy of state-of-the-art question-answering techniques on multi-release system documents, we propose QAMR, a chatbot designed to answer questions across multi-release system documentation. QAMR enhances traditional retrieval-augmented generation (RAG) to ensure accuracy in the face of highly similar yet distinct documentation for different releases. It achieves this through a novel combination of pre-processing, query rewriting, and context selection. In addition, QAMR employs a dual-chunking strategy to enable separately tuned chunk sizes for retrieval and answer generation, improving overall question-answering accuracy. We evaluate QAMR using a public software-engineering benchmark as well as a collection of real-world, multi-release system documents from our industry partner, Ciena. Our evaluation yields five main findings: (1) QAMR outperforms a baseline RAG-based chatbot, achieving an average answer correctness of 88.5% and an average retrieval accuracy of 90%, which correspond to improvements of 16.5% and 12%, respectively. (2) An ablation study shows that QAMR's mechanisms for handling multi-release documents directly improve answer accuracy. (3) Compared to its component-ablated variants, QAMR achieves a 19.6% average gain in answer correctness and a 14.0% average gain in retrieval accuracy over the best ablation. (4) QAMR reduces response time by 8% on average relative to the baseline. (5) The automatically computed accuracy metrics used in our evaluation strongly correlate with expert human assessments, validating the reliability of our methodology.</p></details> | <details><summary>Accep...</summary><p>Accepted for publication in SANER 2026</p></details> |
| **[Fusion2Print: Deep Flash-Non-Flash Fusion for Contactless Fingerprint Matching](https://arxiv.org/abs/2601.02318v1)** | 2026-01-05 | <details><summary>Show</summary><p>Contactless fingerprint recognition offers a hygienic and convenient alternative to contact-based systems, enabling rapid acquisition without latent prints, pressure artifacts, or hygiene risks. However, contactless images often show degraded ridge clarity due to illumination variation, subcutaneous skin discoloration, and specular reflections. Flash captures preserve ridge detail but introduce noise, whereas non-flash captures reduce noise but lower ridge contrast. We propose Fusion2Print (F2P), the first framework to systematically capture and fuse paired flash-non-flash contactless fingerprints. We construct a custom paired dataset, FNF Database, and perform manual flash-non-flash subtraction to isolate ridge-preserving signals. A lightweight attention-based fusion network also integrates both modalities, emphasizing informative channels and suppressing noise, and then a U-Net enhancement module produces an optimally weighted grayscale image. Finally, a deep embedding model with cross-domain compatibility, generates discriminative and robust representations in a unified embedding space compatible with both contactless and contact-based fingerprints for verification. F2P enhances ridge clarity and achieves superior recognition performance (AUC=0.999, EER=1.12%) over single-capture baselines (Verifinger, DeepPrint).</p></details> | <details><summary>15 pa...</summary><p>15 pages, 8 figures, 5 tables. Submitted to ICPR 2026</p></details> |
| **[Tales of the 2025 Los Angeles Fire: Hotwash for Public Health Concerns in Reddit via LLM-Enhanced Topic Modeling](https://arxiv.org/abs/2505.09665v3)** | 2026-01-05 | <details><summary>Show</summary><p>Wildfires have become increasingly frequent, irregular, and severe in recent years. Understanding how affected populations perceive and respond during wildfire crises is critical for timely and empathetic disaster response. Social media platforms offer a crowd-sourced channel to capture evolving public discourse, providing hyperlocal information and insight into public sentiment. This study analyzes Reddit discourse during the 2025 Los Angeles wildfires, spanning from the onset of the disaster to full containment. We collect 385 posts and 114,879 comments related to the Palisades and Eaton fires. We adopt topic modeling methods to identify the latent topics, enhanced by large language models (LLMs) and human-in-the-loop (HITL) refinement. Furthermore, we develop a hierarchical framework to categorize latent topics, consisting of two main categories, Situational Awareness (SA) and Crisis Narratives (CN). The volume of SA category closely aligns with real-world fire progressions, peaking within the first 2-5 days as the fires reach the maximum extent. The most frequent co-occurring category set of public health and safety, loss and damage, and emergency resources expands on a wide range of health-related latent topics, including environmental health, occupational health, and one health. Grief signals and mental health risks consistently accounted for 60 percentage and 40 percentage of CN instances, respectively, with the highest total volume occurring at night. This study contributes the first annotated social media dataset on the 2025 LA fires, and introduces a scalable multi-layer framework that leverages topic modeling for crisis discourse analysis. By identifying persistent public health concerns, our results can inform more empathetic and adaptive strategies for disaster response, public health communication, and future research in comparable climate-related disaster events.</p></details> | <details><summary>Fix t...</summary><p>Fix typos in Method Section. Add data/code availability</p></details> |
| **[Temporal Kolmogorov-Arnold Networks (T-KAN) for High-Frequency Limit Order Book Forecasting: Efficiency, Interpretability, and Alpha Decay](https://arxiv.org/abs/2601.02310v1)** | 2026-01-05 | <details><summary>Show</summary><p>High-Frequency trading (HFT) environments are characterised by large volumes of limit order book (LOB) data, which is notoriously noisy and non-linear. Alpha decay represents a significant challenge, with traditional models such as DeepLOB losing predictive power as the time horizon (k) increases. In this paper, using data from the FI-2010 dataset, we introduce Temporal Kolmogorov-Arnold Networks (T-KAN) to replace the fixed, linear weights of standard LSTMs with learnable B-spline activation functions. This allows the model to learn the 'shape' of market signals as opposed to just their magnitude. This resulted in a 19.1% relative improvement in the F1-score at the k = 100 horizon. The efficacy of T-KAN networks cannot be understated, producing a 132.48% return compared to the -82.76% DeepLOB drawdown under 1.0 bps transaction costs. In addition to this, the T-KAN model proves quite interpretable, with the 'dead-zones' being clearly visible in the splines. The T-KAN architecture is also uniquely optimized for low-latency FPGA implementation via High level Synthesis (HLS). The code for the experiments in this project can be found at https://github.com/AhmadMak/Temporal-Kolmogorov-Arnold-Networks-T-KAN-for-High-Frequency-Limit-Order-Book-Forecasting.</p></details> | <details><summary>8 pag...</summary><p>8 pages, 5 figures, Proposes T-KAN architecture for HFT. Achieves 19.1% F1-score improvement on FI-2010 and 132.48% return in cost-adjusted backtests.Proposes T-KAN architecture for HFT. Achieves 19.1% F1-score improvement on FI-2010 and 132.48% return in cost-adjusted backtests</p></details> |
| **[Classifying several dialectal Nawatl varieties](https://arxiv.org/abs/2601.02303v1)** | 2026-01-05 | <details><summary>Show</summary><p>Mexico is a country with a large number of indigenous languages, among which the most widely spoken is Nawatl, with more than two million people currently speaking it (mainly in North and Central America). Despite its rich cultural heritage, which dates back to the 15th century, Nawatl is a language with few computer resources. The problem is compounded when it comes to its dialectal varieties, with approximately 30 varieties recognised, not counting the different spellings in the written forms of the language. In this research work, we addressed the problem of classifying Nawatl varieties using Machine Learning and Neural Networks.</p></details> | <details><summary>9 pag...</summary><p>9 pages, 5 figures, 4 tables</p></details> |
| **[Generative Site-Specific Beamforming for Next-Generation Spatial Intelligence](https://arxiv.org/abs/2601.02301v1)** | 2026-01-05 | <details><summary>Show</summary><p>This article proposes generative site-specific beamforming (GenSSBF) for next-generation spatial intelligence in wireless networks. Site-specific beamforming (SSBF) has emerged as a promising paradigm to mitigate the channel acquisition bottleneck in multiantenna systems by exploiting environmental priors. However, classical SSBF based on discriminative deep learning struggles: 1) to properly represent the inherent multimodality of wireless propagation and 2) to effectively capture the structural features of beamformers. In contrast, by leveraging conditional generative models, GenSSBF addresses these issues via learning a conditional distribution over feasible beamformers. By doing so, the synthesis of diverse and high-fidelity beam candidates from coarse channel sensing measurements can be guaranteed. This article presents the fundamentals, system designs, and implementation methods of GenSSBF. Case studies in both indoor and outdoor scenarios show that GenSSBF attains near-optimal beamforming gain with ultra-low channel acquisition overhead. Finally, several open research problems are highlighted.</p></details> | 7 pages, 5 figures |
| **[Vectorized Parallel in Time methods for low-order discretizations with application to Porous Media problems](https://arxiv.org/abs/2504.02117v2)** | 2026-01-05 | <details><summary>Show</summary><p>High order methods have shown great potential to overcome performance issues of simulations of partial differential equations (PDEs) on modern hardware, still many users stick to low-order, matrix-based simulations, in particular in porous media applications. Heterogeneous coefficients and low regularity of the solution are reasons not to employ high order discretizations. We present a new approach for the simulation of instationary PDEs that allows to partially mitigate the performance problems. By reformulating the original problem we derive a parallel in time time integrator that increases the arithmetic intensity and introduces additional structure into the problem. By this it helps accelerate matrix-based simulations on modern hardware architectures. Based on a system for multiple time steps we will formulate a matrix equation that can be solved using vectorized solvers like Block Krylov methods. The structure of this approach makes it applicable for a wide range of linear and nonlinear problems. In our numerical experiments we present some first results for three different PDEs, a linear convection-diffusion equation, a nonlinear diffusion-reaction equation and a realistic example based on the Richards' equation.</p></details> |  |
| **[An Automatic Pipeline for the Integration of Python-Based Tools into the Galaxy Platform: Application to the anvi'o Framework](https://arxiv.org/abs/2601.02283v1)** | 2026-01-05 | <details><summary>Show</summary><p>The integration of command-line tools into the Galaxy platform is crucial for making complex computational methods accessible to a broader audience and ensuring reproducible research. However, the manual development of tool wrappers is a time-consuming, error-prone, and knowledge-intensive process. This bottleneck significantly affects the rapid deployment of new and updated tools, creating a gap between tool development and its availability to the scientific community. We have developed a novel, automated approach that directly translates Python tool interfaces into Galaxy-compliant tool wrappers. Our method leverages the argparse library, a standard for command-line argument parsing in Python. By embedding structured metadata within the metavar attribute of input and output arguments, our system programmatically parses the tool's interface to extract all necessary information. This includes parameter types, data formats, help text, and input/output definitions. The system then uses this information to automatically generate a complete and valid Galaxy tool XML wrapper, requiring no manual intervention. To validate the scalability and effectiveness of our approach, we applied it to the anvi'o framework, a comprehensive and complex bioinformatics platform comprising hundreds of individual programs. Our method successfully parsed the argparse definitions for the entire anvi'o suite and generated functional Galaxy tool wrappers. The resulting integration allows for the seamless execution of anvi'o workflows within the Galaxy environment. This work presents a significant advancement in the automation of tool integration for scientific workflow systems. By establishing a convention-based approach using Python's argparse library, we have created a scalable and generalizable solution that dramatically reduces the effort required to make command-line tools available in Galaxy.</p></details> | 26 pages, 5 figures |

## Object Counting
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[Question Answering for Multi-Release Systems: A Case Study at Ciena](https://arxiv.org/abs/2601.02345v1)** | 2026-01-05 | <details><summary>Show</summary><p>Companies regularly have to contend with multi-release systems, where several versions of the same software are in operation simultaneously. Question answering over documents from multi-release systems poses challenges because different releases have distinct yet overlapping documentation. Motivated by the observed inaccuracy of state-of-the-art question-answering techniques on multi-release system documents, we propose QAMR, a chatbot designed to answer questions across multi-release system documentation. QAMR enhances traditional retrieval-augmented generation (RAG) to ensure accuracy in the face of highly similar yet distinct documentation for different releases. It achieves this through a novel combination of pre-processing, query rewriting, and context selection. In addition, QAMR employs a dual-chunking strategy to enable separately tuned chunk sizes for retrieval and answer generation, improving overall question-answering accuracy. We evaluate QAMR using a public software-engineering benchmark as well as a collection of real-world, multi-release system documents from our industry partner, Ciena. Our evaluation yields five main findings: (1) QAMR outperforms a baseline RAG-based chatbot, achieving an average answer correctness of 88.5% and an average retrieval accuracy of 90%, which correspond to improvements of 16.5% and 12%, respectively. (2) An ablation study shows that QAMR's mechanisms for handling multi-release documents directly improve answer accuracy. (3) Compared to its component-ablated variants, QAMR achieves a 19.6% average gain in answer correctness and a 14.0% average gain in retrieval accuracy over the best ablation. (4) QAMR reduces response time by 8% on average relative to the baseline. (5) The automatically computed accuracy metrics used in our evaluation strongly correlate with expert human assessments, validating the reliability of our methodology.</p></details> | <details><summary>Accep...</summary><p>Accepted for publication in SANER 2026</p></details> |
| **[Fusion2Print: Deep Flash-Non-Flash Fusion for Contactless Fingerprint Matching](https://arxiv.org/abs/2601.02318v1)** | 2026-01-05 | <details><summary>Show</summary><p>Contactless fingerprint recognition offers a hygienic and convenient alternative to contact-based systems, enabling rapid acquisition without latent prints, pressure artifacts, or hygiene risks. However, contactless images often show degraded ridge clarity due to illumination variation, subcutaneous skin discoloration, and specular reflections. Flash captures preserve ridge detail but introduce noise, whereas non-flash captures reduce noise but lower ridge contrast. We propose Fusion2Print (F2P), the first framework to systematically capture and fuse paired flash-non-flash contactless fingerprints. We construct a custom paired dataset, FNF Database, and perform manual flash-non-flash subtraction to isolate ridge-preserving signals. A lightweight attention-based fusion network also integrates both modalities, emphasizing informative channels and suppressing noise, and then a U-Net enhancement module produces an optimally weighted grayscale image. Finally, a deep embedding model with cross-domain compatibility, generates discriminative and robust representations in a unified embedding space compatible with both contactless and contact-based fingerprints for verification. F2P enhances ridge clarity and achieves superior recognition performance (AUC=0.999, EER=1.12%) over single-capture baselines (Verifinger, DeepPrint).</p></details> | <details><summary>15 pa...</summary><p>15 pages, 8 figures, 5 tables. Submitted to ICPR 2026</p></details> |
| **[Tales of the 2025 Los Angeles Fire: Hotwash for Public Health Concerns in Reddit via LLM-Enhanced Topic Modeling](https://arxiv.org/abs/2505.09665v3)** | 2026-01-05 | <details><summary>Show</summary><p>Wildfires have become increasingly frequent, irregular, and severe in recent years. Understanding how affected populations perceive and respond during wildfire crises is critical for timely and empathetic disaster response. Social media platforms offer a crowd-sourced channel to capture evolving public discourse, providing hyperlocal information and insight into public sentiment. This study analyzes Reddit discourse during the 2025 Los Angeles wildfires, spanning from the onset of the disaster to full containment. We collect 385 posts and 114,879 comments related to the Palisades and Eaton fires. We adopt topic modeling methods to identify the latent topics, enhanced by large language models (LLMs) and human-in-the-loop (HITL) refinement. Furthermore, we develop a hierarchical framework to categorize latent topics, consisting of two main categories, Situational Awareness (SA) and Crisis Narratives (CN). The volume of SA category closely aligns with real-world fire progressions, peaking within the first 2-5 days as the fires reach the maximum extent. The most frequent co-occurring category set of public health and safety, loss and damage, and emergency resources expands on a wide range of health-related latent topics, including environmental health, occupational health, and one health. Grief signals and mental health risks consistently accounted for 60 percentage and 40 percentage of CN instances, respectively, with the highest total volume occurring at night. This study contributes the first annotated social media dataset on the 2025 LA fires, and introduces a scalable multi-layer framework that leverages topic modeling for crisis discourse analysis. By identifying persistent public health concerns, our results can inform more empathetic and adaptive strategies for disaster response, public health communication, and future research in comparable climate-related disaster events.</p></details> | <details><summary>Fix t...</summary><p>Fix typos in Method Section. Add data/code availability</p></details> |
| **[Temporal Kolmogorov-Arnold Networks (T-KAN) for High-Frequency Limit Order Book Forecasting: Efficiency, Interpretability, and Alpha Decay](https://arxiv.org/abs/2601.02310v1)** | 2026-01-05 | <details><summary>Show</summary><p>High-Frequency trading (HFT) environments are characterised by large volumes of limit order book (LOB) data, which is notoriously noisy and non-linear. Alpha decay represents a significant challenge, with traditional models such as DeepLOB losing predictive power as the time horizon (k) increases. In this paper, using data from the FI-2010 dataset, we introduce Temporal Kolmogorov-Arnold Networks (T-KAN) to replace the fixed, linear weights of standard LSTMs with learnable B-spline activation functions. This allows the model to learn the 'shape' of market signals as opposed to just their magnitude. This resulted in a 19.1% relative improvement in the F1-score at the k = 100 horizon. The efficacy of T-KAN networks cannot be understated, producing a 132.48% return compared to the -82.76% DeepLOB drawdown under 1.0 bps transaction costs. In addition to this, the T-KAN model proves quite interpretable, with the 'dead-zones' being clearly visible in the splines. The T-KAN architecture is also uniquely optimized for low-latency FPGA implementation via High level Synthesis (HLS). The code for the experiments in this project can be found at https://github.com/AhmadMak/Temporal-Kolmogorov-Arnold-Networks-T-KAN-for-High-Frequency-Limit-Order-Book-Forecasting.</p></details> | <details><summary>8 pag...</summary><p>8 pages, 5 figures, Proposes T-KAN architecture for HFT. Achieves 19.1% F1-score improvement on FI-2010 and 132.48% return in cost-adjusted backtests.Proposes T-KAN architecture for HFT. Achieves 19.1% F1-score improvement on FI-2010 and 132.48% return in cost-adjusted backtests</p></details> |
| **[Classifying several dialectal Nawatl varieties](https://arxiv.org/abs/2601.02303v1)** | 2026-01-05 | <details><summary>Show</summary><p>Mexico is a country with a large number of indigenous languages, among which the most widely spoken is Nawatl, with more than two million people currently speaking it (mainly in North and Central America). Despite its rich cultural heritage, which dates back to the 15th century, Nawatl is a language with few computer resources. The problem is compounded when it comes to its dialectal varieties, with approximately 30 varieties recognised, not counting the different spellings in the written forms of the language. In this research work, we addressed the problem of classifying Nawatl varieties using Machine Learning and Neural Networks.</p></details> | <details><summary>9 pag...</summary><p>9 pages, 5 figures, 4 tables</p></details> |
| **[Generative Site-Specific Beamforming for Next-Generation Spatial Intelligence](https://arxiv.org/abs/2601.02301v1)** | 2026-01-05 | <details><summary>Show</summary><p>This article proposes generative site-specific beamforming (GenSSBF) for next-generation spatial intelligence in wireless networks. Site-specific beamforming (SSBF) has emerged as a promising paradigm to mitigate the channel acquisition bottleneck in multiantenna systems by exploiting environmental priors. However, classical SSBF based on discriminative deep learning struggles: 1) to properly represent the inherent multimodality of wireless propagation and 2) to effectively capture the structural features of beamformers. In contrast, by leveraging conditional generative models, GenSSBF addresses these issues via learning a conditional distribution over feasible beamformers. By doing so, the synthesis of diverse and high-fidelity beam candidates from coarse channel sensing measurements can be guaranteed. This article presents the fundamentals, system designs, and implementation methods of GenSSBF. Case studies in both indoor and outdoor scenarios show that GenSSBF attains near-optimal beamforming gain with ultra-low channel acquisition overhead. Finally, several open research problems are highlighted.</p></details> | 7 pages, 5 figures |
| **[SortWaste: A Densely Annotated Dataset for Object Detection in Industrial Waste Sorting](https://arxiv.org/abs/2601.02299v1)** | 2026-01-05 | <details><summary>Show</summary><p>The increasing production of waste, driven by population growth, has created challenges in managing and recycling materials effectively. Manual waste sorting is a common practice; however, it remains inefficient for handling large-scale waste streams and presents health risks for workers. On the other hand, existing automated sorting approaches still struggle with the high variability, clutter, and visual complexity of real-world waste streams. The lack of real-world datasets for waste sorting is a major reason automated systems for this problem are underdeveloped. Accordingly, we introduce SortWaste, a densely annotated object detection dataset collected from a Material Recovery Facility. Additionally, we contribute to standardizing waste detection in sorting lines by proposing ClutterScore, an objective metric that gauges the scene's hardness level using a set of proxies that affect visual complexity (e.g., object count, class and size entropy, and spatial overlap). In addition to these contributions, we provide an extensive benchmark of state-of-the-art object detection models, detailing their results with respect to the hardness level assessed by the proposed metric. Despite achieving promising results (mAP of 59.7% in the plastic-only detection task), performance significantly decreases in highly cluttered scenes. This highlights the need for novel and more challenging datasets on the topic.</p></details> | 9 pages |
| **[An Automatic Pipeline for the Integration of Python-Based Tools into the Galaxy Platform: Application to the anvi'o Framework](https://arxiv.org/abs/2601.02283v1)** | 2026-01-05 | <details><summary>Show</summary><p>The integration of command-line tools into the Galaxy platform is crucial for making complex computational methods accessible to a broader audience and ensuring reproducible research. However, the manual development of tool wrappers is a time-consuming, error-prone, and knowledge-intensive process. This bottleneck significantly affects the rapid deployment of new and updated tools, creating a gap between tool development and its availability to the scientific community. We have developed a novel, automated approach that directly translates Python tool interfaces into Galaxy-compliant tool wrappers. Our method leverages the argparse library, a standard for command-line argument parsing in Python. By embedding structured metadata within the metavar attribute of input and output arguments, our system programmatically parses the tool's interface to extract all necessary information. This includes parameter types, data formats, help text, and input/output definitions. The system then uses this information to automatically generate a complete and valid Galaxy tool XML wrapper, requiring no manual intervention. To validate the scalability and effectiveness of our approach, we applied it to the anvi'o framework, a comprehensive and complex bioinformatics platform comprising hundreds of individual programs. Our method successfully parsed the argparse definitions for the entire anvi'o suite and generated functional Galaxy tool wrappers. The resulting integration allows for the seamless execution of anvi'o workflows within the Galaxy environment. This work presents a significant advancement in the automation of tool integration for scientific workflow systems. By establishing a convention-based approach using Python's argparse library, we have created a scalable and generalizable solution that dramatically reduces the effort required to make command-line tools available in Galaxy.</p></details> | 26 pages, 5 figures |

## Image Caption
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[Question Answering for Multi-Release Systems: A Case Study at Ciena](https://arxiv.org/abs/2601.02345v1)** | 2026-01-05 | <details><summary>Show</summary><p>Companies regularly have to contend with multi-release systems, where several versions of the same software are in operation simultaneously. Question answering over documents from multi-release systems poses challenges because different releases have distinct yet overlapping documentation. Motivated by the observed inaccuracy of state-of-the-art question-answering techniques on multi-release system documents, we propose QAMR, a chatbot designed to answer questions across multi-release system documentation. QAMR enhances traditional retrieval-augmented generation (RAG) to ensure accuracy in the face of highly similar yet distinct documentation for different releases. It achieves this through a novel combination of pre-processing, query rewriting, and context selection. In addition, QAMR employs a dual-chunking strategy to enable separately tuned chunk sizes for retrieval and answer generation, improving overall question-answering accuracy. We evaluate QAMR using a public software-engineering benchmark as well as a collection of real-world, multi-release system documents from our industry partner, Ciena. Our evaluation yields five main findings: (1) QAMR outperforms a baseline RAG-based chatbot, achieving an average answer correctness of 88.5% and an average retrieval accuracy of 90%, which correspond to improvements of 16.5% and 12%, respectively. (2) An ablation study shows that QAMR's mechanisms for handling multi-release documents directly improve answer accuracy. (3) Compared to its component-ablated variants, QAMR achieves a 19.6% average gain in answer correctness and a 14.0% average gain in retrieval accuracy over the best ablation. (4) QAMR reduces response time by 8% on average relative to the baseline. (5) The automatically computed accuracy metrics used in our evaluation strongly correlate with expert human assessments, validating the reliability of our methodology.</p></details> | <details><summary>Accep...</summary><p>Accepted for publication in SANER 2026</p></details> |
| **[Fusion2Print: Deep Flash-Non-Flash Fusion for Contactless Fingerprint Matching](https://arxiv.org/abs/2601.02318v1)** | 2026-01-05 | <details><summary>Show</summary><p>Contactless fingerprint recognition offers a hygienic and convenient alternative to contact-based systems, enabling rapid acquisition without latent prints, pressure artifacts, or hygiene risks. However, contactless images often show degraded ridge clarity due to illumination variation, subcutaneous skin discoloration, and specular reflections. Flash captures preserve ridge detail but introduce noise, whereas non-flash captures reduce noise but lower ridge contrast. We propose Fusion2Print (F2P), the first framework to systematically capture and fuse paired flash-non-flash contactless fingerprints. We construct a custom paired dataset, FNF Database, and perform manual flash-non-flash subtraction to isolate ridge-preserving signals. A lightweight attention-based fusion network also integrates both modalities, emphasizing informative channels and suppressing noise, and then a U-Net enhancement module produces an optimally weighted grayscale image. Finally, a deep embedding model with cross-domain compatibility, generates discriminative and robust representations in a unified embedding space compatible with both contactless and contact-based fingerprints for verification. F2P enhances ridge clarity and achieves superior recognition performance (AUC=0.999, EER=1.12%) over single-capture baselines (Verifinger, DeepPrint).</p></details> | <details><summary>15 pa...</summary><p>15 pages, 8 figures, 5 tables. Submitted to ICPR 2026</p></details> |
| **[Tales of the 2025 Los Angeles Fire: Hotwash for Public Health Concerns in Reddit via LLM-Enhanced Topic Modeling](https://arxiv.org/abs/2505.09665v3)** | 2026-01-05 | <details><summary>Show</summary><p>Wildfires have become increasingly frequent, irregular, and severe in recent years. Understanding how affected populations perceive and respond during wildfire crises is critical for timely and empathetic disaster response. Social media platforms offer a crowd-sourced channel to capture evolving public discourse, providing hyperlocal information and insight into public sentiment. This study analyzes Reddit discourse during the 2025 Los Angeles wildfires, spanning from the onset of the disaster to full containment. We collect 385 posts and 114,879 comments related to the Palisades and Eaton fires. We adopt topic modeling methods to identify the latent topics, enhanced by large language models (LLMs) and human-in-the-loop (HITL) refinement. Furthermore, we develop a hierarchical framework to categorize latent topics, consisting of two main categories, Situational Awareness (SA) and Crisis Narratives (CN). The volume of SA category closely aligns with real-world fire progressions, peaking within the first 2-5 days as the fires reach the maximum extent. The most frequent co-occurring category set of public health and safety, loss and damage, and emergency resources expands on a wide range of health-related latent topics, including environmental health, occupational health, and one health. Grief signals and mental health risks consistently accounted for 60 percentage and 40 percentage of CN instances, respectively, with the highest total volume occurring at night. This study contributes the first annotated social media dataset on the 2025 LA fires, and introduces a scalable multi-layer framework that leverages topic modeling for crisis discourse analysis. By identifying persistent public health concerns, our results can inform more empathetic and adaptive strategies for disaster response, public health communication, and future research in comparable climate-related disaster events.</p></details> | <details><summary>Fix t...</summary><p>Fix typos in Method Section. Add data/code availability</p></details> |
| **[Temporal Kolmogorov-Arnold Networks (T-KAN) for High-Frequency Limit Order Book Forecasting: Efficiency, Interpretability, and Alpha Decay](https://arxiv.org/abs/2601.02310v1)** | 2026-01-05 | <details><summary>Show</summary><p>High-Frequency trading (HFT) environments are characterised by large volumes of limit order book (LOB) data, which is notoriously noisy and non-linear. Alpha decay represents a significant challenge, with traditional models such as DeepLOB losing predictive power as the time horizon (k) increases. In this paper, using data from the FI-2010 dataset, we introduce Temporal Kolmogorov-Arnold Networks (T-KAN) to replace the fixed, linear weights of standard LSTMs with learnable B-spline activation functions. This allows the model to learn the 'shape' of market signals as opposed to just their magnitude. This resulted in a 19.1% relative improvement in the F1-score at the k = 100 horizon. The efficacy of T-KAN networks cannot be understated, producing a 132.48% return compared to the -82.76% DeepLOB drawdown under 1.0 bps transaction costs. In addition to this, the T-KAN model proves quite interpretable, with the 'dead-zones' being clearly visible in the splines. The T-KAN architecture is also uniquely optimized for low-latency FPGA implementation via High level Synthesis (HLS). The code for the experiments in this project can be found at https://github.com/AhmadMak/Temporal-Kolmogorov-Arnold-Networks-T-KAN-for-High-Frequency-Limit-Order-Book-Forecasting.</p></details> | <details><summary>8 pag...</summary><p>8 pages, 5 figures, Proposes T-KAN architecture for HFT. Achieves 19.1% F1-score improvement on FI-2010 and 132.48% return in cost-adjusted backtests.Proposes T-KAN architecture for HFT. Achieves 19.1% F1-score improvement on FI-2010 and 132.48% return in cost-adjusted backtests</p></details> |
| **[Classifying several dialectal Nawatl varieties](https://arxiv.org/abs/2601.02303v1)** | 2026-01-05 | <details><summary>Show</summary><p>Mexico is a country with a large number of indigenous languages, among which the most widely spoken is Nawatl, with more than two million people currently speaking it (mainly in North and Central America). Despite its rich cultural heritage, which dates back to the 15th century, Nawatl is a language with few computer resources. The problem is compounded when it comes to its dialectal varieties, with approximately 30 varieties recognised, not counting the different spellings in the written forms of the language. In this research work, we addressed the problem of classifying Nawatl varieties using Machine Learning and Neural Networks.</p></details> | <details><summary>9 pag...</summary><p>9 pages, 5 figures, 4 tables</p></details> |
| **[Generative Site-Specific Beamforming for Next-Generation Spatial Intelligence](https://arxiv.org/abs/2601.02301v1)** | 2026-01-05 | <details><summary>Show</summary><p>This article proposes generative site-specific beamforming (GenSSBF) for next-generation spatial intelligence in wireless networks. Site-specific beamforming (SSBF) has emerged as a promising paradigm to mitigate the channel acquisition bottleneck in multiantenna systems by exploiting environmental priors. However, classical SSBF based on discriminative deep learning struggles: 1) to properly represent the inherent multimodality of wireless propagation and 2) to effectively capture the structural features of beamformers. In contrast, by leveraging conditional generative models, GenSSBF addresses these issues via learning a conditional distribution over feasible beamformers. By doing so, the synthesis of diverse and high-fidelity beam candidates from coarse channel sensing measurements can be guaranteed. This article presents the fundamentals, system designs, and implementation methods of GenSSBF. Case studies in both indoor and outdoor scenarios show that GenSSBF attains near-optimal beamforming gain with ultra-low channel acquisition overhead. Finally, several open research problems are highlighted.</p></details> | 7 pages, 5 figures |
| **[An Automatic Pipeline for the Integration of Python-Based Tools into the Galaxy Platform: Application to the anvi'o Framework](https://arxiv.org/abs/2601.02283v1)** | 2026-01-05 | <details><summary>Show</summary><p>The integration of command-line tools into the Galaxy platform is crucial for making complex computational methods accessible to a broader audience and ensuring reproducible research. However, the manual development of tool wrappers is a time-consuming, error-prone, and knowledge-intensive process. This bottleneck significantly affects the rapid deployment of new and updated tools, creating a gap between tool development and its availability to the scientific community. We have developed a novel, automated approach that directly translates Python tool interfaces into Galaxy-compliant tool wrappers. Our method leverages the argparse library, a standard for command-line argument parsing in Python. By embedding structured metadata within the metavar attribute of input and output arguments, our system programmatically parses the tool's interface to extract all necessary information. This includes parameter types, data formats, help text, and input/output definitions. The system then uses this information to automatically generate a complete and valid Galaxy tool XML wrapper, requiring no manual intervention. To validate the scalability and effectiveness of our approach, we applied it to the anvi'o framework, a comprehensive and complex bioinformatics platform comprising hundreds of individual programs. Our method successfully parsed the argparse definitions for the entire anvi'o suite and generated functional Galaxy tool wrappers. The resulting integration allows for the seamless execution of anvi'o workflows within the Galaxy environment. This work presents a significant advancement in the automation of tool integration for scientific workflow systems. By establishing a convention-based approach using Python's argparse library, we have created a scalable and generalizable solution that dramatically reduces the effort required to make command-line tools available in Galaxy.</p></details> | 26 pages, 5 figures |

## Describe
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[PRIMAD-LID: A Developed Framework for Computational Reproducibility](https://arxiv.org/abs/2601.02349v1)** | 2026-01-05 | <details><summary>Show</summary><p>Over the past decade alongside increased focus on computational reproducibility significant efforts have been made to define reproducibility. However, these definitions provide a textual description rather than a framework. The community has sought conceptual frameworks that identify all factors that must be controlled and described for credible computational reproducibility. The PRIMAD model was initially introduced to address inconsistencies in terminology surrounding computational reproducibility by outlining six key factors: P (Platforms), R (Research objective), I (Implementations), M (Methods), A (Actors), and D (Data). Subsequently various studies across different fields adopted the model and proposed extensions. However, these contributions remain fragmented and require systematic integration and cross-disciplinary validation. To bridge this gap and recognising that PRIMAD provides a broadly applicable framework for reproducibility in computational science, this work undertakes a focused investigation of the PRIMAD model. It combines the models previous extensions into a unified framework suitable for diverse research contexts. The result is PRIMAD-LID, a discipline-diagnostic reproducibility framework that retains the original six PRIMAD dimensions and enhances each with three overarching modifiers: Lifespan (temporal qualifier), Interpretation (contextual reasoning) and Depth (necessary granularity), thereby establishing a more cohesive and robust foundation for computational reproducibility practices.</p></details> |  |
| **[Question Answering for Multi-Release Systems: A Case Study at Ciena](https://arxiv.org/abs/2601.02345v1)** | 2026-01-05 | <details><summary>Show</summary><p>Companies regularly have to contend with multi-release systems, where several versions of the same software are in operation simultaneously. Question answering over documents from multi-release systems poses challenges because different releases have distinct yet overlapping documentation. Motivated by the observed inaccuracy of state-of-the-art question-answering techniques on multi-release system documents, we propose QAMR, a chatbot designed to answer questions across multi-release system documentation. QAMR enhances traditional retrieval-augmented generation (RAG) to ensure accuracy in the face of highly similar yet distinct documentation for different releases. It achieves this through a novel combination of pre-processing, query rewriting, and context selection. In addition, QAMR employs a dual-chunking strategy to enable separately tuned chunk sizes for retrieval and answer generation, improving overall question-answering accuracy. We evaluate QAMR using a public software-engineering benchmark as well as a collection of real-world, multi-release system documents from our industry partner, Ciena. Our evaluation yields five main findings: (1) QAMR outperforms a baseline RAG-based chatbot, achieving an average answer correctness of 88.5% and an average retrieval accuracy of 90%, which correspond to improvements of 16.5% and 12%, respectively. (2) An ablation study shows that QAMR's mechanisms for handling multi-release documents directly improve answer accuracy. (3) Compared to its component-ablated variants, QAMR achieves a 19.6% average gain in answer correctness and a 14.0% average gain in retrieval accuracy over the best ablation. (4) QAMR reduces response time by 8% on average relative to the baseline. (5) The automatically computed accuracy metrics used in our evaluation strongly correlate with expert human assessments, validating the reliability of our methodology.</p></details> | <details><summary>Accep...</summary><p>Accepted for publication in SANER 2026</p></details> |
| **[Fusion2Print: Deep Flash-Non-Flash Fusion for Contactless Fingerprint Matching](https://arxiv.org/abs/2601.02318v1)** | 2026-01-05 | <details><summary>Show</summary><p>Contactless fingerprint recognition offers a hygienic and convenient alternative to contact-based systems, enabling rapid acquisition without latent prints, pressure artifacts, or hygiene risks. However, contactless images often show degraded ridge clarity due to illumination variation, subcutaneous skin discoloration, and specular reflections. Flash captures preserve ridge detail but introduce noise, whereas non-flash captures reduce noise but lower ridge contrast. We propose Fusion2Print (F2P), the first framework to systematically capture and fuse paired flash-non-flash contactless fingerprints. We construct a custom paired dataset, FNF Database, and perform manual flash-non-flash subtraction to isolate ridge-preserving signals. A lightweight attention-based fusion network also integrates both modalities, emphasizing informative channels and suppressing noise, and then a U-Net enhancement module produces an optimally weighted grayscale image. Finally, a deep embedding model with cross-domain compatibility, generates discriminative and robust representations in a unified embedding space compatible with both contactless and contact-based fingerprints for verification. F2P enhances ridge clarity and achieves superior recognition performance (AUC=0.999, EER=1.12%) over single-capture baselines (Verifinger, DeepPrint).</p></details> | <details><summary>15 pa...</summary><p>15 pages, 8 figures, 5 tables. Submitted to ICPR 2026</p></details> |
| **[Tales of the 2025 Los Angeles Fire: Hotwash for Public Health Concerns in Reddit via LLM-Enhanced Topic Modeling](https://arxiv.org/abs/2505.09665v3)** | 2026-01-05 | <details><summary>Show</summary><p>Wildfires have become increasingly frequent, irregular, and severe in recent years. Understanding how affected populations perceive and respond during wildfire crises is critical for timely and empathetic disaster response. Social media platforms offer a crowd-sourced channel to capture evolving public discourse, providing hyperlocal information and insight into public sentiment. This study analyzes Reddit discourse during the 2025 Los Angeles wildfires, spanning from the onset of the disaster to full containment. We collect 385 posts and 114,879 comments related to the Palisades and Eaton fires. We adopt topic modeling methods to identify the latent topics, enhanced by large language models (LLMs) and human-in-the-loop (HITL) refinement. Furthermore, we develop a hierarchical framework to categorize latent topics, consisting of two main categories, Situational Awareness (SA) and Crisis Narratives (CN). The volume of SA category closely aligns with real-world fire progressions, peaking within the first 2-5 days as the fires reach the maximum extent. The most frequent co-occurring category set of public health and safety, loss and damage, and emergency resources expands on a wide range of health-related latent topics, including environmental health, occupational health, and one health. Grief signals and mental health risks consistently accounted for 60 percentage and 40 percentage of CN instances, respectively, with the highest total volume occurring at night. This study contributes the first annotated social media dataset on the 2025 LA fires, and introduces a scalable multi-layer framework that leverages topic modeling for crisis discourse analysis. By identifying persistent public health concerns, our results can inform more empathetic and adaptive strategies for disaster response, public health communication, and future research in comparable climate-related disaster events.</p></details> | <details><summary>Fix t...</summary><p>Fix typos in Method Section. Add data/code availability</p></details> |
| **[Temporal Kolmogorov-Arnold Networks (T-KAN) for High-Frequency Limit Order Book Forecasting: Efficiency, Interpretability, and Alpha Decay](https://arxiv.org/abs/2601.02310v1)** | 2026-01-05 | <details><summary>Show</summary><p>High-Frequency trading (HFT) environments are characterised by large volumes of limit order book (LOB) data, which is notoriously noisy and non-linear. Alpha decay represents a significant challenge, with traditional models such as DeepLOB losing predictive power as the time horizon (k) increases. In this paper, using data from the FI-2010 dataset, we introduce Temporal Kolmogorov-Arnold Networks (T-KAN) to replace the fixed, linear weights of standard LSTMs with learnable B-spline activation functions. This allows the model to learn the 'shape' of market signals as opposed to just their magnitude. This resulted in a 19.1% relative improvement in the F1-score at the k = 100 horizon. The efficacy of T-KAN networks cannot be understated, producing a 132.48% return compared to the -82.76% DeepLOB drawdown under 1.0 bps transaction costs. In addition to this, the T-KAN model proves quite interpretable, with the 'dead-zones' being clearly visible in the splines. The T-KAN architecture is also uniquely optimized for low-latency FPGA implementation via High level Synthesis (HLS). The code for the experiments in this project can be found at https://github.com/AhmadMak/Temporal-Kolmogorov-Arnold-Networks-T-KAN-for-High-Frequency-Limit-Order-Book-Forecasting.</p></details> | <details><summary>8 pag...</summary><p>8 pages, 5 figures, Proposes T-KAN architecture for HFT. Achieves 19.1% F1-score improvement on FI-2010 and 132.48% return in cost-adjusted backtests.Proposes T-KAN architecture for HFT. Achieves 19.1% F1-score improvement on FI-2010 and 132.48% return in cost-adjusted backtests</p></details> |
| **[Classifying several dialectal Nawatl varieties](https://arxiv.org/abs/2601.02303v1)** | 2026-01-05 | <details><summary>Show</summary><p>Mexico is a country with a large number of indigenous languages, among which the most widely spoken is Nawatl, with more than two million people currently speaking it (mainly in North and Central America). Despite its rich cultural heritage, which dates back to the 15th century, Nawatl is a language with few computer resources. The problem is compounded when it comes to its dialectal varieties, with approximately 30 varieties recognised, not counting the different spellings in the written forms of the language. In this research work, we addressed the problem of classifying Nawatl varieties using Machine Learning and Neural Networks.</p></details> | <details><summary>9 pag...</summary><p>9 pages, 5 figures, 4 tables</p></details> |
| **[Generative Site-Specific Beamforming for Next-Generation Spatial Intelligence](https://arxiv.org/abs/2601.02301v1)** | 2026-01-05 | <details><summary>Show</summary><p>This article proposes generative site-specific beamforming (GenSSBF) for next-generation spatial intelligence in wireless networks. Site-specific beamforming (SSBF) has emerged as a promising paradigm to mitigate the channel acquisition bottleneck in multiantenna systems by exploiting environmental priors. However, classical SSBF based on discriminative deep learning struggles: 1) to properly represent the inherent multimodality of wireless propagation and 2) to effectively capture the structural features of beamformers. In contrast, by leveraging conditional generative models, GenSSBF addresses these issues via learning a conditional distribution over feasible beamformers. By doing so, the synthesis of diverse and high-fidelity beam candidates from coarse channel sensing measurements can be guaranteed. This article presents the fundamentals, system designs, and implementation methods of GenSSBF. Case studies in both indoor and outdoor scenarios show that GenSSBF attains near-optimal beamforming gain with ultra-low channel acquisition overhead. Finally, several open research problems are highlighted.</p></details> | 7 pages, 5 figures |
| **[An Automatic Pipeline for the Integration of Python-Based Tools into the Galaxy Platform: Application to the anvi'o Framework](https://arxiv.org/abs/2601.02283v1)** | 2026-01-05 | <details><summary>Show</summary><p>The integration of command-line tools into the Galaxy platform is crucial for making complex computational methods accessible to a broader audience and ensuring reproducible research. However, the manual development of tool wrappers is a time-consuming, error-prone, and knowledge-intensive process. This bottleneck significantly affects the rapid deployment of new and updated tools, creating a gap between tool development and its availability to the scientific community. We have developed a novel, automated approach that directly translates Python tool interfaces into Galaxy-compliant tool wrappers. Our method leverages the argparse library, a standard for command-line argument parsing in Python. By embedding structured metadata within the metavar attribute of input and output arguments, our system programmatically parses the tool's interface to extract all necessary information. This includes parameter types, data formats, help text, and input/output definitions. The system then uses this information to automatically generate a complete and valid Galaxy tool XML wrapper, requiring no manual intervention. To validate the scalability and effectiveness of our approach, we applied it to the anvi'o framework, a comprehensive and complex bioinformatics platform comprising hundreds of individual programs. Our method successfully parsed the argparse definitions for the entire anvi'o suite and generated functional Galaxy tool wrappers. The resulting integration allows for the seamless execution of anvi'o workflows within the Galaxy environment. This work presents a significant advancement in the automation of tool integration for scientific workflow systems. By establishing a convention-based approach using Python's argparse library, we have created a scalable and generalizable solution that dramatically reduces the effort required to make command-line tools available in Galaxy.</p></details> | 26 pages, 5 figures |
| **[Schwarz maps with symmetry](https://arxiv.org/abs/2601.02282v1)** | 2026-01-05 | <details><summary>Show</summary><p>The theory of symmetry of quantum mechanical systems is applied to study the structure and properties of several classes of relevant maps in quantum information theory: CPTP, PPT and Schwarz maps. First, we develop the general structure that equivariant maps $:\mathcal A \to \mathcal B$ between $C^\ast$-algebras satisfy. Then, we undertake a systematic study of unital, Hermiticity-preserving maps that are equivariant under natural unitary group actions. Schwarz maps satisfy Kadison's inequality $(X^\ast X) \geq (X)^\ast (X)$ and form an intermediate class between positive and completely positive maps. We completely classify $U(n)$-equivariant on $M_n(\mathbb C)$ and determine those that are completely positive and Schwarz. Partial classifications are then obtained for the weaker $DU(n)$-equivariance (diagonal unitary symmetry) and for tensor-product symmetries $U(n_1) \otimes U(n_2)$. In each case, the parameter regions where $$ is Schwarz or completely positive are described by explicit algebraic inequalities, and their geometry is illustrated. Finally, we further show that the $U(n)$-equivariant family satisfies $\mathrm{PPT} \iff \mathrm{EB}$, while the $DU(2)$, symmetric $DU(3)$, $U(2) \otimes U(2)$ and $U(2) \otimes U(3)$, families obey the $\mathrm{PPT}^2$ conjecture through a direct symmetry argument. These results reveal how group symmetry controls the structure of non-completely positive maps and provide new concrete examples where the $\mathrm{PPT}^2$ property holds.</p></details> | 38 pages, 2 figures |

## Light Weight
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[Question Answering for Multi-Release Systems: A Case Study at Ciena](https://arxiv.org/abs/2601.02345v1)** | 2026-01-05 | <details><summary>Show</summary><p>Companies regularly have to contend with multi-release systems, where several versions of the same software are in operation simultaneously. Question answering over documents from multi-release systems poses challenges because different releases have distinct yet overlapping documentation. Motivated by the observed inaccuracy of state-of-the-art question-answering techniques on multi-release system documents, we propose QAMR, a chatbot designed to answer questions across multi-release system documentation. QAMR enhances traditional retrieval-augmented generation (RAG) to ensure accuracy in the face of highly similar yet distinct documentation for different releases. It achieves this through a novel combination of pre-processing, query rewriting, and context selection. In addition, QAMR employs a dual-chunking strategy to enable separately tuned chunk sizes for retrieval and answer generation, improving overall question-answering accuracy. We evaluate QAMR using a public software-engineering benchmark as well as a collection of real-world, multi-release system documents from our industry partner, Ciena. Our evaluation yields five main findings: (1) QAMR outperforms a baseline RAG-based chatbot, achieving an average answer correctness of 88.5% and an average retrieval accuracy of 90%, which correspond to improvements of 16.5% and 12%, respectively. (2) An ablation study shows that QAMR's mechanisms for handling multi-release documents directly improve answer accuracy. (3) Compared to its component-ablated variants, QAMR achieves a 19.6% average gain in answer correctness and a 14.0% average gain in retrieval accuracy over the best ablation. (4) QAMR reduces response time by 8% on average relative to the baseline. (5) The automatically computed accuracy metrics used in our evaluation strongly correlate with expert human assessments, validating the reliability of our methodology.</p></details> | <details><summary>Accep...</summary><p>Accepted for publication in SANER 2026</p></details> |
| **[Fusion2Print: Deep Flash-Non-Flash Fusion for Contactless Fingerprint Matching](https://arxiv.org/abs/2601.02318v1)** | 2026-01-05 | <details><summary>Show</summary><p>Contactless fingerprint recognition offers a hygienic and convenient alternative to contact-based systems, enabling rapid acquisition without latent prints, pressure artifacts, or hygiene risks. However, contactless images often show degraded ridge clarity due to illumination variation, subcutaneous skin discoloration, and specular reflections. Flash captures preserve ridge detail but introduce noise, whereas non-flash captures reduce noise but lower ridge contrast. We propose Fusion2Print (F2P), the first framework to systematically capture and fuse paired flash-non-flash contactless fingerprints. We construct a custom paired dataset, FNF Database, and perform manual flash-non-flash subtraction to isolate ridge-preserving signals. A lightweight attention-based fusion network also integrates both modalities, emphasizing informative channels and suppressing noise, and then a U-Net enhancement module produces an optimally weighted grayscale image. Finally, a deep embedding model with cross-domain compatibility, generates discriminative and robust representations in a unified embedding space compatible with both contactless and contact-based fingerprints for verification. F2P enhances ridge clarity and achieves superior recognition performance (AUC=0.999, EER=1.12%) over single-capture baselines (Verifinger, DeepPrint).</p></details> | <details><summary>15 pa...</summary><p>15 pages, 8 figures, 5 tables. Submitted to ICPR 2026</p></details> |
| **[Tales of the 2025 Los Angeles Fire: Hotwash for Public Health Concerns in Reddit via LLM-Enhanced Topic Modeling](https://arxiv.org/abs/2505.09665v3)** | 2026-01-05 | <details><summary>Show</summary><p>Wildfires have become increasingly frequent, irregular, and severe in recent years. Understanding how affected populations perceive and respond during wildfire crises is critical for timely and empathetic disaster response. Social media platforms offer a crowd-sourced channel to capture evolving public discourse, providing hyperlocal information and insight into public sentiment. This study analyzes Reddit discourse during the 2025 Los Angeles wildfires, spanning from the onset of the disaster to full containment. We collect 385 posts and 114,879 comments related to the Palisades and Eaton fires. We adopt topic modeling methods to identify the latent topics, enhanced by large language models (LLMs) and human-in-the-loop (HITL) refinement. Furthermore, we develop a hierarchical framework to categorize latent topics, consisting of two main categories, Situational Awareness (SA) and Crisis Narratives (CN). The volume of SA category closely aligns with real-world fire progressions, peaking within the first 2-5 days as the fires reach the maximum extent. The most frequent co-occurring category set of public health and safety, loss and damage, and emergency resources expands on a wide range of health-related latent topics, including environmental health, occupational health, and one health. Grief signals and mental health risks consistently accounted for 60 percentage and 40 percentage of CN instances, respectively, with the highest total volume occurring at night. This study contributes the first annotated social media dataset on the 2025 LA fires, and introduces a scalable multi-layer framework that leverages topic modeling for crisis discourse analysis. By identifying persistent public health concerns, our results can inform more empathetic and adaptive strategies for disaster response, public health communication, and future research in comparable climate-related disaster events.</p></details> | <details><summary>Fix t...</summary><p>Fix typos in Method Section. Add data/code availability</p></details> |
| **[Temporal Kolmogorov-Arnold Networks (T-KAN) for High-Frequency Limit Order Book Forecasting: Efficiency, Interpretability, and Alpha Decay](https://arxiv.org/abs/2601.02310v1)** | 2026-01-05 | <details><summary>Show</summary><p>High-Frequency trading (HFT) environments are characterised by large volumes of limit order book (LOB) data, which is notoriously noisy and non-linear. Alpha decay represents a significant challenge, with traditional models such as DeepLOB losing predictive power as the time horizon (k) increases. In this paper, using data from the FI-2010 dataset, we introduce Temporal Kolmogorov-Arnold Networks (T-KAN) to replace the fixed, linear weights of standard LSTMs with learnable B-spline activation functions. This allows the model to learn the 'shape' of market signals as opposed to just their magnitude. This resulted in a 19.1% relative improvement in the F1-score at the k = 100 horizon. The efficacy of T-KAN networks cannot be understated, producing a 132.48% return compared to the -82.76% DeepLOB drawdown under 1.0 bps transaction costs. In addition to this, the T-KAN model proves quite interpretable, with the 'dead-zones' being clearly visible in the splines. The T-KAN architecture is also uniquely optimized for low-latency FPGA implementation via High level Synthesis (HLS). The code for the experiments in this project can be found at https://github.com/AhmadMak/Temporal-Kolmogorov-Arnold-Networks-T-KAN-for-High-Frequency-Limit-Order-Book-Forecasting.</p></details> | <details><summary>8 pag...</summary><p>8 pages, 5 figures, Proposes T-KAN architecture for HFT. Achieves 19.1% F1-score improvement on FI-2010 and 132.48% return in cost-adjusted backtests.Proposes T-KAN architecture for HFT. Achieves 19.1% F1-score improvement on FI-2010 and 132.48% return in cost-adjusted backtests</p></details> |
| **[Classifying several dialectal Nawatl varieties](https://arxiv.org/abs/2601.02303v1)** | 2026-01-05 | <details><summary>Show</summary><p>Mexico is a country with a large number of indigenous languages, among which the most widely spoken is Nawatl, with more than two million people currently speaking it (mainly in North and Central America). Despite its rich cultural heritage, which dates back to the 15th century, Nawatl is a language with few computer resources. The problem is compounded when it comes to its dialectal varieties, with approximately 30 varieties recognised, not counting the different spellings in the written forms of the language. In this research work, we addressed the problem of classifying Nawatl varieties using Machine Learning and Neural Networks.</p></details> | <details><summary>9 pag...</summary><p>9 pages, 5 figures, 4 tables</p></details> |
| **[Generative Site-Specific Beamforming for Next-Generation Spatial Intelligence](https://arxiv.org/abs/2601.02301v1)** | 2026-01-05 | <details><summary>Show</summary><p>This article proposes generative site-specific beamforming (GenSSBF) for next-generation spatial intelligence in wireless networks. Site-specific beamforming (SSBF) has emerged as a promising paradigm to mitigate the channel acquisition bottleneck in multiantenna systems by exploiting environmental priors. However, classical SSBF based on discriminative deep learning struggles: 1) to properly represent the inherent multimodality of wireless propagation and 2) to effectively capture the structural features of beamformers. In contrast, by leveraging conditional generative models, GenSSBF addresses these issues via learning a conditional distribution over feasible beamformers. By doing so, the synthesis of diverse and high-fidelity beam candidates from coarse channel sensing measurements can be guaranteed. This article presents the fundamentals, system designs, and implementation methods of GenSSBF. Case studies in both indoor and outdoor scenarios show that GenSSBF attains near-optimal beamforming gain with ultra-low channel acquisition overhead. Finally, several open research problems are highlighted.</p></details> | 7 pages, 5 figures |
| **[An Automatic Pipeline for the Integration of Python-Based Tools into the Galaxy Platform: Application to the anvi'o Framework](https://arxiv.org/abs/2601.02283v1)** | 2026-01-05 | <details><summary>Show</summary><p>The integration of command-line tools into the Galaxy platform is crucial for making complex computational methods accessible to a broader audience and ensuring reproducible research. However, the manual development of tool wrappers is a time-consuming, error-prone, and knowledge-intensive process. This bottleneck significantly affects the rapid deployment of new and updated tools, creating a gap between tool development and its availability to the scientific community. We have developed a novel, automated approach that directly translates Python tool interfaces into Galaxy-compliant tool wrappers. Our method leverages the argparse library, a standard for command-line argument parsing in Python. By embedding structured metadata within the metavar attribute of input and output arguments, our system programmatically parses the tool's interface to extract all necessary information. This includes parameter types, data formats, help text, and input/output definitions. The system then uses this information to automatically generate a complete and valid Galaxy tool XML wrapper, requiring no manual intervention. To validate the scalability and effectiveness of our approach, we applied it to the anvi'o framework, a comprehensive and complex bioinformatics platform comprising hundreds of individual programs. Our method successfully parsed the argparse definitions for the entire anvi'o suite and generated functional Galaxy tool wrappers. The resulting integration allows for the seamless execution of anvi'o workflows within the Galaxy environment. This work presents a significant advancement in the automation of tool integration for scientific workflow systems. By establishing a convention-based approach using Python's argparse library, we have created a scalable and generalizable solution that dramatically reduces the effort required to make command-line tools available in Galaxy.</p></details> | 26 pages, 5 figures |

## Class Incremental
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[Question Answering for Multi-Release Systems: A Case Study at Ciena](https://arxiv.org/abs/2601.02345v1)** | 2026-01-05 | <details><summary>Show</summary><p>Companies regularly have to contend with multi-release systems, where several versions of the same software are in operation simultaneously. Question answering over documents from multi-release systems poses challenges because different releases have distinct yet overlapping documentation. Motivated by the observed inaccuracy of state-of-the-art question-answering techniques on multi-release system documents, we propose QAMR, a chatbot designed to answer questions across multi-release system documentation. QAMR enhances traditional retrieval-augmented generation (RAG) to ensure accuracy in the face of highly similar yet distinct documentation for different releases. It achieves this through a novel combination of pre-processing, query rewriting, and context selection. In addition, QAMR employs a dual-chunking strategy to enable separately tuned chunk sizes for retrieval and answer generation, improving overall question-answering accuracy. We evaluate QAMR using a public software-engineering benchmark as well as a collection of real-world, multi-release system documents from our industry partner, Ciena. Our evaluation yields five main findings: (1) QAMR outperforms a baseline RAG-based chatbot, achieving an average answer correctness of 88.5% and an average retrieval accuracy of 90%, which correspond to improvements of 16.5% and 12%, respectively. (2) An ablation study shows that QAMR's mechanisms for handling multi-release documents directly improve answer accuracy. (3) Compared to its component-ablated variants, QAMR achieves a 19.6% average gain in answer correctness and a 14.0% average gain in retrieval accuracy over the best ablation. (4) QAMR reduces response time by 8% on average relative to the baseline. (5) The automatically computed accuracy metrics used in our evaluation strongly correlate with expert human assessments, validating the reliability of our methodology.</p></details> | <details><summary>Accep...</summary><p>Accepted for publication in SANER 2026</p></details> |
| **[Fusion2Print: Deep Flash-Non-Flash Fusion for Contactless Fingerprint Matching](https://arxiv.org/abs/2601.02318v1)** | 2026-01-05 | <details><summary>Show</summary><p>Contactless fingerprint recognition offers a hygienic and convenient alternative to contact-based systems, enabling rapid acquisition without latent prints, pressure artifacts, or hygiene risks. However, contactless images often show degraded ridge clarity due to illumination variation, subcutaneous skin discoloration, and specular reflections. Flash captures preserve ridge detail but introduce noise, whereas non-flash captures reduce noise but lower ridge contrast. We propose Fusion2Print (F2P), the first framework to systematically capture and fuse paired flash-non-flash contactless fingerprints. We construct a custom paired dataset, FNF Database, and perform manual flash-non-flash subtraction to isolate ridge-preserving signals. A lightweight attention-based fusion network also integrates both modalities, emphasizing informative channels and suppressing noise, and then a U-Net enhancement module produces an optimally weighted grayscale image. Finally, a deep embedding model with cross-domain compatibility, generates discriminative and robust representations in a unified embedding space compatible with both contactless and contact-based fingerprints for verification. F2P enhances ridge clarity and achieves superior recognition performance (AUC=0.999, EER=1.12%) over single-capture baselines (Verifinger, DeepPrint).</p></details> | <details><summary>15 pa...</summary><p>15 pages, 8 figures, 5 tables. Submitted to ICPR 2026</p></details> |
| **[Tales of the 2025 Los Angeles Fire: Hotwash for Public Health Concerns in Reddit via LLM-Enhanced Topic Modeling](https://arxiv.org/abs/2505.09665v3)** | 2026-01-05 | <details><summary>Show</summary><p>Wildfires have become increasingly frequent, irregular, and severe in recent years. Understanding how affected populations perceive and respond during wildfire crises is critical for timely and empathetic disaster response. Social media platforms offer a crowd-sourced channel to capture evolving public discourse, providing hyperlocal information and insight into public sentiment. This study analyzes Reddit discourse during the 2025 Los Angeles wildfires, spanning from the onset of the disaster to full containment. We collect 385 posts and 114,879 comments related to the Palisades and Eaton fires. We adopt topic modeling methods to identify the latent topics, enhanced by large language models (LLMs) and human-in-the-loop (HITL) refinement. Furthermore, we develop a hierarchical framework to categorize latent topics, consisting of two main categories, Situational Awareness (SA) and Crisis Narratives (CN). The volume of SA category closely aligns with real-world fire progressions, peaking within the first 2-5 days as the fires reach the maximum extent. The most frequent co-occurring category set of public health and safety, loss and damage, and emergency resources expands on a wide range of health-related latent topics, including environmental health, occupational health, and one health. Grief signals and mental health risks consistently accounted for 60 percentage and 40 percentage of CN instances, respectively, with the highest total volume occurring at night. This study contributes the first annotated social media dataset on the 2025 LA fires, and introduces a scalable multi-layer framework that leverages topic modeling for crisis discourse analysis. By identifying persistent public health concerns, our results can inform more empathetic and adaptive strategies for disaster response, public health communication, and future research in comparable climate-related disaster events.</p></details> | <details><summary>Fix t...</summary><p>Fix typos in Method Section. Add data/code availability</p></details> |
| **[Temporal Kolmogorov-Arnold Networks (T-KAN) for High-Frequency Limit Order Book Forecasting: Efficiency, Interpretability, and Alpha Decay](https://arxiv.org/abs/2601.02310v1)** | 2026-01-05 | <details><summary>Show</summary><p>High-Frequency trading (HFT) environments are characterised by large volumes of limit order book (LOB) data, which is notoriously noisy and non-linear. Alpha decay represents a significant challenge, with traditional models such as DeepLOB losing predictive power as the time horizon (k) increases. In this paper, using data from the FI-2010 dataset, we introduce Temporal Kolmogorov-Arnold Networks (T-KAN) to replace the fixed, linear weights of standard LSTMs with learnable B-spline activation functions. This allows the model to learn the 'shape' of market signals as opposed to just their magnitude. This resulted in a 19.1% relative improvement in the F1-score at the k = 100 horizon. The efficacy of T-KAN networks cannot be understated, producing a 132.48% return compared to the -82.76% DeepLOB drawdown under 1.0 bps transaction costs. In addition to this, the T-KAN model proves quite interpretable, with the 'dead-zones' being clearly visible in the splines. The T-KAN architecture is also uniquely optimized for low-latency FPGA implementation via High level Synthesis (HLS). The code for the experiments in this project can be found at https://github.com/AhmadMak/Temporal-Kolmogorov-Arnold-Networks-T-KAN-for-High-Frequency-Limit-Order-Book-Forecasting.</p></details> | <details><summary>8 pag...</summary><p>8 pages, 5 figures, Proposes T-KAN architecture for HFT. Achieves 19.1% F1-score improvement on FI-2010 and 132.48% return in cost-adjusted backtests.Proposes T-KAN architecture for HFT. Achieves 19.1% F1-score improvement on FI-2010 and 132.48% return in cost-adjusted backtests</p></details> |
| **[Classifying several dialectal Nawatl varieties](https://arxiv.org/abs/2601.02303v1)** | 2026-01-05 | <details><summary>Show</summary><p>Mexico is a country with a large number of indigenous languages, among which the most widely spoken is Nawatl, with more than two million people currently speaking it (mainly in North and Central America). Despite its rich cultural heritage, which dates back to the 15th century, Nawatl is a language with few computer resources. The problem is compounded when it comes to its dialectal varieties, with approximately 30 varieties recognised, not counting the different spellings in the written forms of the language. In this research work, we addressed the problem of classifying Nawatl varieties using Machine Learning and Neural Networks.</p></details> | <details><summary>9 pag...</summary><p>9 pages, 5 figures, 4 tables</p></details> |
| **[Generative Site-Specific Beamforming for Next-Generation Spatial Intelligence](https://arxiv.org/abs/2601.02301v1)** | 2026-01-05 | <details><summary>Show</summary><p>This article proposes generative site-specific beamforming (GenSSBF) for next-generation spatial intelligence in wireless networks. Site-specific beamforming (SSBF) has emerged as a promising paradigm to mitigate the channel acquisition bottleneck in multiantenna systems by exploiting environmental priors. However, classical SSBF based on discriminative deep learning struggles: 1) to properly represent the inherent multimodality of wireless propagation and 2) to effectively capture the structural features of beamformers. In contrast, by leveraging conditional generative models, GenSSBF addresses these issues via learning a conditional distribution over feasible beamformers. By doing so, the synthesis of diverse and high-fidelity beam candidates from coarse channel sensing measurements can be guaranteed. This article presents the fundamentals, system designs, and implementation methods of GenSSBF. Case studies in both indoor and outdoor scenarios show that GenSSBF attains near-optimal beamforming gain with ultra-low channel acquisition overhead. Finally, several open research problems are highlighted.</p></details> | 7 pages, 5 figures |
| **[An Automatic Pipeline for the Integration of Python-Based Tools into the Galaxy Platform: Application to the anvi'o Framework](https://arxiv.org/abs/2601.02283v1)** | 2026-01-05 | <details><summary>Show</summary><p>The integration of command-line tools into the Galaxy platform is crucial for making complex computational methods accessible to a broader audience and ensuring reproducible research. However, the manual development of tool wrappers is a time-consuming, error-prone, and knowledge-intensive process. This bottleneck significantly affects the rapid deployment of new and updated tools, creating a gap between tool development and its availability to the scientific community. We have developed a novel, automated approach that directly translates Python tool interfaces into Galaxy-compliant tool wrappers. Our method leverages the argparse library, a standard for command-line argument parsing in Python. By embedding structured metadata within the metavar attribute of input and output arguments, our system programmatically parses the tool's interface to extract all necessary information. This includes parameter types, data formats, help text, and input/output definitions. The system then uses this information to automatically generate a complete and valid Galaxy tool XML wrapper, requiring no manual intervention. To validate the scalability and effectiveness of our approach, we applied it to the anvi'o framework, a comprehensive and complex bioinformatics platform comprising hundreds of individual programs. Our method successfully parsed the argparse definitions for the entire anvi'o suite and generated functional Galaxy tool wrappers. The resulting integration allows for the seamless execution of anvi'o workflows within the Galaxy environment. This work presents a significant advancement in the automation of tool integration for scientific workflow systems. By establishing a convention-based approach using Python's argparse library, we have created a scalable and generalizable solution that dramatically reduces the effort required to make command-line tools available in Galaxy.</p></details> | 26 pages, 5 figures |

