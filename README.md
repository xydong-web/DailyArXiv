# Daily Papers
The project automatically fetches the latest papers from arXiv based on keywords.

The subheadings in the README file represent the search keywords.

Only the most recent articles for each keyword are retained, up to a maximum of 100 papers.

You can click the 'Watch' button to receive daily email notifications.

Last update: 2025-12-30

## Molecular
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[Schwarz Information Criterion Aided Multi-Armed Bandit for Decentralized Resource Allocation in Dynamic LoRa Networks](https://arxiv.org/abs/2512.22089v1)** | 2025-12-26 | <details><summary>Show</summary><p>This paper proposes a lightweight distributed learning method for transmission parameter selection in Long Range (LoRa) networks that can adapt to dynamic communication environments. In the proposed method, each LoRa End Device (ED) employs the Upper Confidence Bound (UCB)1-tuned algorithm to select transmission parameters including channel, transmission power, and bandwidth. The transmission parameters are selected based on the acknowledgment (ACK) feedback returned from the gateway after each transmission and the corresponding transmission energy consumption. Hence, it enables devices to simultaneously optimize transmission success rate and energy efficiency in a fully distributed manner. However, although UCB1-tuned based method is effective under stationary conditions, it suffers from slow adaptation in dynamic environments due to its strong reliance on historical observations. To address this limitation, we integrate the Schwarz Information Criterion (SIC) to our proposed method. SIC is adopted because it enables low-cost detection of changes in the communication environment, making it suitable for implementation on resource-constrained LoRa EDs. When a change is detected by SIC, the learning history of UCB1-tuned is reset, allowing rapid re-learning under the new conditions. Experimental results using real LoRa devices demonstrate that the proposed method achieves superior transmission success rate, energy efficiency, and adaptability compared with the conventional UCB1-tuned algorithm without SIC.</p></details> | 6 pages, 5 figures |
| **[Random state comonads encode cellular automata evaluation](https://arxiv.org/abs/2512.22067v1)** | 2025-12-26 | <details><summary>Show</summary><p>Cellular automata (CA) are quintessential ALife and ubiquitous in many studies of collective behaviour and emergence, from morphogenesis to social dynamics and even brain modelling. Recently, there has been an increased interest in formalising CA, theoretically through category theory and practically in terms of a functional programming paradigm. Unfortunately, these remain either in the realm of simple implementations lacking important practical features, or too abstract and conceptually inaccessible to be useful to the ALife community at large. In this paper, we present a brief and accessible introduction to a category-theoretical model of CA computation through a practical implementation in Haskell. We instantiate arrays as comonads with state and random generators, allowing stochastic behaviour not currently supported in other known implementations. We also emphasise the importance of functional implementations for complex systems: thanks to the Curry-Howard-Lambek isomorphism, functional programs facilitate a mapping between simulation, system rules or semantics, and categorical descriptions, which may advance our understanding and development of generalised theories of emergent behaviour. Using this implementation, we show case studies of four famous CA models: first Wolfram's CA in 1D, then Conway's game of life, Greenberg-Hasings excitable cells, and the stochastic Forest Fire model in 2D, and present directions for an extension to N dimensions. Finally, we suggest that the comonadic model can encode arbitrary topologies and propose future directions for a comonadic network.</p></details> | 5 pages, 5 figures |
| **[M2RU: Memristive Minion Recurrent Unit for On-Chip Continual Learning at the Edge](https://arxiv.org/abs/2512.17299v2)** | 2025-12-26 | <details><summary>Show</summary><p>Continual learning on edge platforms remains challenging because recurrent networks depend on energy-intensive training procedures and frequent data movement that are impractical for embedded deployments. This work introduces M2RU, a mixed-signal architecture that implements the minion recurrent unit for efficient temporal processing with on-chip continual learning. The architecture integrates weighted-bit streaming, which enables multi-bit digital inputs to be processed in crossbars without high-resolution conversion, and an experience replay mechanism that stabilizes learning under domain shifts. M2RU achieves 15 GOPS at 48.62 mW, corresponding to 312 GOPS per watt, and maintains accuracy within 5 percent of software baselines on sequential MNIST and CIFAR-10 tasks. Compared with a CMOS digital design, the accelerator provides 29X improvement in energy efficiency. Device-aware analysis shows an expected operational lifetime of 12.2 years under continual learning workloads. These results establish M2RU as a scalable and energy-efficient platform for real-time adaptation in edge-level temporal intelligence.</p></details> |  |
| **[Backdoor Attacks on Prompt-Driven Video Segmentation Foundation Models](https://arxiv.org/abs/2512.22046v1)** | 2025-12-26 | <details><summary>Show</summary><p>Prompt-driven Video Segmentation Foundation Models (VSFMs) such as SAM2 are increasingly deployed in applications like autonomous driving and digital pathology, raising concerns about backdoor threats. Surprisingly, we find that directly transferring classic backdoor attacks (e.g., BadNet) to VSFMs is almost ineffective, with ASR below 5\%. To understand this, we study encoder gradients and attention maps and observe that conventional training keeps gradients for clean and triggered samples largely aligned, while attention still focuses on the true object, preventing the encoder from learning a distinct trigger-related representation. To address this challenge, we propose BadVSFM, the first backdoor framework tailored to prompt-driven VSFMs. BadVSFM uses a two-stage strategy: (1) steer the image encoder so triggered frames map to a designated target embedding while clean frames remain aligned with a clean reference encoder; (2) train the mask decoder so that, across prompt types, triggered frame-prompt pairs produce a shared target mask, while clean outputs stay close to a reference decoder. Extensive experiments on two datasets and five VSFMs show that BadVSFM achieves strong, controllable backdoor effects under diverse triggers and prompts while preserving clean segmentation quality. Ablations over losses, stages, targets, trigger settings, and poisoning rates demonstrate robustness to reasonable hyperparameter changes and confirm the necessity of the two-stage design. Finally, gradient-conflict analysis and attention visualizations show that BadVSFM separates triggered and clean representations and shifts attention to trigger regions, while four representative defenses remain largely ineffective, revealing an underexplored vulnerability in current VSFMs.</p></details> |  |
| **[From In Silico to In Vitro: Evaluating Molecule Generative Models for Hit Generation](https://arxiv.org/abs/2512.22031v1)** | 2025-12-26 | <details><summary>Show</summary><p>Hit identification is a critical yet resource-intensive step in the drug discovery pipeline, traditionally relying on high-throughput screening of large compound libraries. Despite advancements in virtual screening, these methods remain time-consuming and costly. Recent progress in deep learning has enabled the development of generative models capable of learning complex molecular representations and generating novel compounds de novo. However, using ML to replace the entire drug-discovery pipeline is highly challenging. In this work, we rather investigate whether generative models can replace one step of the pipeline: hit-like molecule generation. To the best of our knowledge, this is the first study to explicitly frame hit-like molecule generation as a standalone task and empirically test whether generative models can directly support this stage of the drug discovery pipeline. Specifically, we investigate if such models can be trained to generate hit-like molecules, enabling direct incorporation into, or even substitution of, traditional hit identification workflows. We propose an evaluation framework tailored to this task, integrating physicochemical, structural, and bioactivity-related criteria within a multi-stage filtering pipeline that defines the hit-like chemical space. Two autoregressive and one diffusion-based generative models were benchmarked across various datasets and training settings, with outputs assessed using standard metrics and target-specific docking scores. Our results show that these models can generate valid, diverse, and biologically relevant compounds across multiple targets, with a few selected GSK-3$Î²$ hits synthesized and confirmed active in vitro. We also identify key limitations in current evaluation metrics and available training data.</p></details> |  |
| **[Direction Finding with Sparse Arrays Based on Variable Window Size Spatial Smoothing](https://arxiv.org/abs/2512.22024v1)** | 2025-12-26 | <details><summary>Show</summary><p>In this work, we introduce a variable window size (VWS) spatial smoothing framework that enhances coarray-based direction of arrival (DOA) estimation for sparse linear arrays. By compressing the smoothing aperture, the proposed VWS Coarray MUSIC (VWS-CA-MUSIC) and VWS Coarray root-MUSIC (VWS-CA-rMUSIC) algorithms replace part of the perturbed rank-one outer products in the smoothed coarray data with unperturbed low-rank additional terms, increasing the separation between signal and noise subspaces, while preserving the signal subspace span. We also derive the bounds that guarantees identifiability, by limiting the values that can be assumed by the compression parameter. Simulations with sparse geometries reveal significant performance improvements and complexity savings relative to the fixed-window coarray MUSIC method.</p></details> | 2 figures, 5 pages |

## Molecular Generation
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[Schwarz Information Criterion Aided Multi-Armed Bandit for Decentralized Resource Allocation in Dynamic LoRa Networks](https://arxiv.org/abs/2512.22089v1)** | 2025-12-26 | <details><summary>Show</summary><p>This paper proposes a lightweight distributed learning method for transmission parameter selection in Long Range (LoRa) networks that can adapt to dynamic communication environments. In the proposed method, each LoRa End Device (ED) employs the Upper Confidence Bound (UCB)1-tuned algorithm to select transmission parameters including channel, transmission power, and bandwidth. The transmission parameters are selected based on the acknowledgment (ACK) feedback returned from the gateway after each transmission and the corresponding transmission energy consumption. Hence, it enables devices to simultaneously optimize transmission success rate and energy efficiency in a fully distributed manner. However, although UCB1-tuned based method is effective under stationary conditions, it suffers from slow adaptation in dynamic environments due to its strong reliance on historical observations. To address this limitation, we integrate the Schwarz Information Criterion (SIC) to our proposed method. SIC is adopted because it enables low-cost detection of changes in the communication environment, making it suitable for implementation on resource-constrained LoRa EDs. When a change is detected by SIC, the learning history of UCB1-tuned is reset, allowing rapid re-learning under the new conditions. Experimental results using real LoRa devices demonstrate that the proposed method achieves superior transmission success rate, energy efficiency, and adaptability compared with the conventional UCB1-tuned algorithm without SIC.</p></details> | 6 pages, 5 figures |
| **[Random state comonads encode cellular automata evaluation](https://arxiv.org/abs/2512.22067v1)** | 2025-12-26 | <details><summary>Show</summary><p>Cellular automata (CA) are quintessential ALife and ubiquitous in many studies of collective behaviour and emergence, from morphogenesis to social dynamics and even brain modelling. Recently, there has been an increased interest in formalising CA, theoretically through category theory and practically in terms of a functional programming paradigm. Unfortunately, these remain either in the realm of simple implementations lacking important practical features, or too abstract and conceptually inaccessible to be useful to the ALife community at large. In this paper, we present a brief and accessible introduction to a category-theoretical model of CA computation through a practical implementation in Haskell. We instantiate arrays as comonads with state and random generators, allowing stochastic behaviour not currently supported in other known implementations. We also emphasise the importance of functional implementations for complex systems: thanks to the Curry-Howard-Lambek isomorphism, functional programs facilitate a mapping between simulation, system rules or semantics, and categorical descriptions, which may advance our understanding and development of generalised theories of emergent behaviour. Using this implementation, we show case studies of four famous CA models: first Wolfram's CA in 1D, then Conway's game of life, Greenberg-Hasings excitable cells, and the stochastic Forest Fire model in 2D, and present directions for an extension to N dimensions. Finally, we suggest that the comonadic model can encode arbitrary topologies and propose future directions for a comonadic network.</p></details> | 5 pages, 5 figures |
| **[M2RU: Memristive Minion Recurrent Unit for On-Chip Continual Learning at the Edge](https://arxiv.org/abs/2512.17299v2)** | 2025-12-26 | <details><summary>Show</summary><p>Continual learning on edge platforms remains challenging because recurrent networks depend on energy-intensive training procedures and frequent data movement that are impractical for embedded deployments. This work introduces M2RU, a mixed-signal architecture that implements the minion recurrent unit for efficient temporal processing with on-chip continual learning. The architecture integrates weighted-bit streaming, which enables multi-bit digital inputs to be processed in crossbars without high-resolution conversion, and an experience replay mechanism that stabilizes learning under domain shifts. M2RU achieves 15 GOPS at 48.62 mW, corresponding to 312 GOPS per watt, and maintains accuracy within 5 percent of software baselines on sequential MNIST and CIFAR-10 tasks. Compared with a CMOS digital design, the accelerator provides 29X improvement in energy efficiency. Device-aware analysis shows an expected operational lifetime of 12.2 years under continual learning workloads. These results establish M2RU as a scalable and energy-efficient platform for real-time adaptation in edge-level temporal intelligence.</p></details> |  |
| **[Backdoor Attacks on Prompt-Driven Video Segmentation Foundation Models](https://arxiv.org/abs/2512.22046v1)** | 2025-12-26 | <details><summary>Show</summary><p>Prompt-driven Video Segmentation Foundation Models (VSFMs) such as SAM2 are increasingly deployed in applications like autonomous driving and digital pathology, raising concerns about backdoor threats. Surprisingly, we find that directly transferring classic backdoor attacks (e.g., BadNet) to VSFMs is almost ineffective, with ASR below 5\%. To understand this, we study encoder gradients and attention maps and observe that conventional training keeps gradients for clean and triggered samples largely aligned, while attention still focuses on the true object, preventing the encoder from learning a distinct trigger-related representation. To address this challenge, we propose BadVSFM, the first backdoor framework tailored to prompt-driven VSFMs. BadVSFM uses a two-stage strategy: (1) steer the image encoder so triggered frames map to a designated target embedding while clean frames remain aligned with a clean reference encoder; (2) train the mask decoder so that, across prompt types, triggered frame-prompt pairs produce a shared target mask, while clean outputs stay close to a reference decoder. Extensive experiments on two datasets and five VSFMs show that BadVSFM achieves strong, controllable backdoor effects under diverse triggers and prompts while preserving clean segmentation quality. Ablations over losses, stages, targets, trigger settings, and poisoning rates demonstrate robustness to reasonable hyperparameter changes and confirm the necessity of the two-stage design. Finally, gradient-conflict analysis and attention visualizations show that BadVSFM separates triggered and clean representations and shifts attention to trigger regions, while four representative defenses remain largely ineffective, revealing an underexplored vulnerability in current VSFMs.</p></details> |  |
| **[Direction Finding with Sparse Arrays Based on Variable Window Size Spatial Smoothing](https://arxiv.org/abs/2512.22024v1)** | 2025-12-26 | <details><summary>Show</summary><p>In this work, we introduce a variable window size (VWS) spatial smoothing framework that enhances coarray-based direction of arrival (DOA) estimation for sparse linear arrays. By compressing the smoothing aperture, the proposed VWS Coarray MUSIC (VWS-CA-MUSIC) and VWS Coarray root-MUSIC (VWS-CA-rMUSIC) algorithms replace part of the perturbed rank-one outer products in the smoothed coarray data with unperturbed low-rank additional terms, increasing the separation between signal and noise subspaces, while preserving the signal subspace span. We also derive the bounds that guarantees identifiability, by limiting the values that can be assumed by the compression parameter. Simulations with sparse geometries reveal significant performance improvements and complexity savings relative to the fixed-window coarray MUSIC method.</p></details> | 2 figures, 5 pages |
| **[Non-Resolution Reasoning (NRR): A Computational Framework for Contextual Identity and Ambiguity Preservation](https://arxiv.org/abs/2512.13478v5)** | 2025-12-26 | <details><summary>Show</summary><p>Current AI systems exhibit a fundamental limitation: they resolve ambiguity prematurely. This premature semantic collapse--collapsing multiple valid interpretations into single outputs--stems from classical identity assumptions in neural architectures. We propose Non-Resolution Reasoning (NRR), treating ambiguity retention as a valid reasoning mode. NRR introduces three principles: (1) Non-Identity ($A \neq A$)--the same symbol refers to different entities across contexts; (2) Approximate Identity ($A \approx A$)--entities share partial overlap without being identical; (3) Non-Resolution--conflicting interpretations coexist without forced convergence. We formalize these through Multi-Vector Embeddings, Non-Collapsing Attention, and Contextual Identity Tracking (CIT). Functional verification via Turn 1 Entropy measurement shows NRR-lite maintains high entropy ($H = 0.63$) at ambiguous turns while standard architectures collapse early ($H = 0.10$), demonstrating that NRR preserves interpretive flexibility until context arrives. The question is not whether AI should resolve ambiguity, but when, how, and under whose control.</p></details> | <details><summary>v5: M...</summary><p>v5: Major revision to Section 5. Replaced accuracy-based OOD evaluation with entropy-based functional verification (proof-of-concept). Clarified scope as architectural demonstration rather than comparative benchmark</p></details> |
| **[Research on a hybrid LSTM-CNN-Attention model for text-based web content classification](https://arxiv.org/abs/2512.18475v2)** | 2025-12-26 | <details><summary>Show</summary><p>This study presents a hybrid deep learning architecture that integrates LSTM, CNN, and an Attention mechanism to enhance the classification of web content based on text. Pretrained GloVe embeddings are used to represent words as dense vectors that preserve semantic similarity. The CNN layer extracts local n-gram patterns and lexical features, while the LSTM layer models long-range dependencies and sequential structure. The integrated Attention mechanism enables the model to focus selectively on the most informative parts of the input sequence. A 5-fold cross-validation setup was used to assess the robustness and generalizability of the proposed solution. Experimental results show that the hybrid LSTM-CNN-Attention model achieved outstanding performance, with an accuracy of 0.98, precision of 0.94, recall of 0.92, and F1-score of 0.93. These results surpass the performance of baseline models based solely on CNNs, LSTMs, or transformer-based classifiers such as BERT. The combination of neural network components enabled the model to effectively capture both fine-grained text structures and broader semantic context. Furthermore, the use of GloVe embeddings provided an efficient and effective representation of textual data, making the model suitable for integration into systems with real-time or near-real-time requirements. The proposed hybrid architecture demonstrates high effectiveness in text-based web content classification, particularly in tasks requiring both syntactic feature extraction and semantic interpretation. By combining presented mechanisms, the model addresses the limitations of individual architectures and achieves improved generalization. These findings support the broader use of hybrid deep learning approaches in NLP applications, especially where complex, unstructured textual data must be processed and classified with high reliability.</p></details> | <details><summary>10 pa...</summary><p>10 pages, 5 figures, 2 tables. Published by Radio Electronics Computer Science Control 2025</p></details> |
| **[Super-LIO: A Robust and Efficient LiDAR-Inertial Odometry System with a Compact Mapping Strategy](https://arxiv.org/abs/2509.05723v2)** | 2025-12-26 | <details><summary>Show</summary><p>LiDAR-Inertial Odometry (LIO) is a foundational technique for autonomous systems, yet its deployment on resource-constrained platforms remains challenging due to computational and memory limitations. We propose Super-LIO, a robust LIO system that demands both high performance and accuracy, ideal for applications such as aerial robots and mobile autonomous systems. At the core of Super-LIO is a compact octo-voxel-based map structure, termed OctVox, that limits each voxel to eight fused subvoxels, enabling strict point density control and incremental denoising during map updates. This design enables a simple yet efficient and accurate map structure, which can be easily integrated into existing LIO frameworks. Additionally, Super-LIO designs a heuristic-guided KNN strategy (HKNN) that accelerates the correspondence search by leveraging spatial locality, further reducing runtime overhead. We evaluated the proposed system using four publicly available datasets and several self-collected datasets, totaling more than 30 sequences. Extensive testing on both X86 and ARM platforms confirms that Super-LIO offers superior efficiency and robustness, while maintaining competitive accuracy. Super-LIO processes each frame approximately 73% faster than SOTA, while consuming less CPU resources. The system is fully open-source and plug-and-play compatible with a wide range of LiDAR sensors and platforms. The implementation is available at: https://github.com/Liansheng-Wang/Super-LIO.git</p></details> | 8 pages, 5 figures |

## Graph Neural Networks
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[Schwarz Information Criterion Aided Multi-Armed Bandit for Decentralized Resource Allocation in Dynamic LoRa Networks](https://arxiv.org/abs/2512.22089v1)** | 2025-12-26 | <details><summary>Show</summary><p>This paper proposes a lightweight distributed learning method for transmission parameter selection in Long Range (LoRa) networks that can adapt to dynamic communication environments. In the proposed method, each LoRa End Device (ED) employs the Upper Confidence Bound (UCB)1-tuned algorithm to select transmission parameters including channel, transmission power, and bandwidth. The transmission parameters are selected based on the acknowledgment (ACK) feedback returned from the gateway after each transmission and the corresponding transmission energy consumption. Hence, it enables devices to simultaneously optimize transmission success rate and energy efficiency in a fully distributed manner. However, although UCB1-tuned based method is effective under stationary conditions, it suffers from slow adaptation in dynamic environments due to its strong reliance on historical observations. To address this limitation, we integrate the Schwarz Information Criterion (SIC) to our proposed method. SIC is adopted because it enables low-cost detection of changes in the communication environment, making it suitable for implementation on resource-constrained LoRa EDs. When a change is detected by SIC, the learning history of UCB1-tuned is reset, allowing rapid re-learning under the new conditions. Experimental results using real LoRa devices demonstrate that the proposed method achieves superior transmission success rate, energy efficiency, and adaptability compared with the conventional UCB1-tuned algorithm without SIC.</p></details> | 6 pages, 5 figures |
| **[Random state comonads encode cellular automata evaluation](https://arxiv.org/abs/2512.22067v1)** | 2025-12-26 | <details><summary>Show</summary><p>Cellular automata (CA) are quintessential ALife and ubiquitous in many studies of collective behaviour and emergence, from morphogenesis to social dynamics and even brain modelling. Recently, there has been an increased interest in formalising CA, theoretically through category theory and practically in terms of a functional programming paradigm. Unfortunately, these remain either in the realm of simple implementations lacking important practical features, or too abstract and conceptually inaccessible to be useful to the ALife community at large. In this paper, we present a brief and accessible introduction to a category-theoretical model of CA computation through a practical implementation in Haskell. We instantiate arrays as comonads with state and random generators, allowing stochastic behaviour not currently supported in other known implementations. We also emphasise the importance of functional implementations for complex systems: thanks to the Curry-Howard-Lambek isomorphism, functional programs facilitate a mapping between simulation, system rules or semantics, and categorical descriptions, which may advance our understanding and development of generalised theories of emergent behaviour. Using this implementation, we show case studies of four famous CA models: first Wolfram's CA in 1D, then Conway's game of life, Greenberg-Hasings excitable cells, and the stochastic Forest Fire model in 2D, and present directions for an extension to N dimensions. Finally, we suggest that the comonadic model can encode arbitrary topologies and propose future directions for a comonadic network.</p></details> | 5 pages, 5 figures |
| **[M2RU: Memristive Minion Recurrent Unit for On-Chip Continual Learning at the Edge](https://arxiv.org/abs/2512.17299v2)** | 2025-12-26 | <details><summary>Show</summary><p>Continual learning on edge platforms remains challenging because recurrent networks depend on energy-intensive training procedures and frequent data movement that are impractical for embedded deployments. This work introduces M2RU, a mixed-signal architecture that implements the minion recurrent unit for efficient temporal processing with on-chip continual learning. The architecture integrates weighted-bit streaming, which enables multi-bit digital inputs to be processed in crossbars without high-resolution conversion, and an experience replay mechanism that stabilizes learning under domain shifts. M2RU achieves 15 GOPS at 48.62 mW, corresponding to 312 GOPS per watt, and maintains accuracy within 5 percent of software baselines on sequential MNIST and CIFAR-10 tasks. Compared with a CMOS digital design, the accelerator provides 29X improvement in energy efficiency. Device-aware analysis shows an expected operational lifetime of 12.2 years under continual learning workloads. These results establish M2RU as a scalable and energy-efficient platform for real-time adaptation in edge-level temporal intelligence.</p></details> |  |
| **[Backdoor Attacks on Prompt-Driven Video Segmentation Foundation Models](https://arxiv.org/abs/2512.22046v1)** | 2025-12-26 | <details><summary>Show</summary><p>Prompt-driven Video Segmentation Foundation Models (VSFMs) such as SAM2 are increasingly deployed in applications like autonomous driving and digital pathology, raising concerns about backdoor threats. Surprisingly, we find that directly transferring classic backdoor attacks (e.g., BadNet) to VSFMs is almost ineffective, with ASR below 5\%. To understand this, we study encoder gradients and attention maps and observe that conventional training keeps gradients for clean and triggered samples largely aligned, while attention still focuses on the true object, preventing the encoder from learning a distinct trigger-related representation. To address this challenge, we propose BadVSFM, the first backdoor framework tailored to prompt-driven VSFMs. BadVSFM uses a two-stage strategy: (1) steer the image encoder so triggered frames map to a designated target embedding while clean frames remain aligned with a clean reference encoder; (2) train the mask decoder so that, across prompt types, triggered frame-prompt pairs produce a shared target mask, while clean outputs stay close to a reference decoder. Extensive experiments on two datasets and five VSFMs show that BadVSFM achieves strong, controllable backdoor effects under diverse triggers and prompts while preserving clean segmentation quality. Ablations over losses, stages, targets, trigger settings, and poisoning rates demonstrate robustness to reasonable hyperparameter changes and confirm the necessity of the two-stage design. Finally, gradient-conflict analysis and attention visualizations show that BadVSFM separates triggered and clean representations and shifts attention to trigger regions, while four representative defenses remain largely ineffective, revealing an underexplored vulnerability in current VSFMs.</p></details> |  |
| **[Direction Finding with Sparse Arrays Based on Variable Window Size Spatial Smoothing](https://arxiv.org/abs/2512.22024v1)** | 2025-12-26 | <details><summary>Show</summary><p>In this work, we introduce a variable window size (VWS) spatial smoothing framework that enhances coarray-based direction of arrival (DOA) estimation for sparse linear arrays. By compressing the smoothing aperture, the proposed VWS Coarray MUSIC (VWS-CA-MUSIC) and VWS Coarray root-MUSIC (VWS-CA-rMUSIC) algorithms replace part of the perturbed rank-one outer products in the smoothed coarray data with unperturbed low-rank additional terms, increasing the separation between signal and noise subspaces, while preserving the signal subspace span. We also derive the bounds that guarantees identifiability, by limiting the values that can be assumed by the compression parameter. Simulations with sparse geometries reveal significant performance improvements and complexity savings relative to the fixed-window coarray MUSIC method.</p></details> | 2 figures, 5 pages |
| **[Efficient Curvature-aware Graph Network](https://arxiv.org/abs/2511.01443v2)** | 2025-12-26 | <details><summary>Show</summary><p>Graph curvature provides geometric priors for Graph Neural Networks (GNNs), enhancing their ability to model complex graph structures, particularly in terms of structural awareness, robustness, and theoretical interpretability. Among existing methods, Ollivier-Ricci curvature has been extensively studied due to its strong geometric interpretability, effectively characterizing the local geometric distribution between nodes. However, its prohibitively high computational complexity limits its applicability to large-scale graph datasets. To address this challenge, we propose a novel graph curvature measure--Effective Resistance Curvature--which quantifies the ease of message passing along graph edges using the effective resistance between node pairs, instead of the optimal transport distance. This method significantly outperforms Ollivier-Ricci curvature in computational efficiency while preserving comparable geometric expressiveness. Theoretically, we prove the low computational complexity of effective resistance curvature and establish its substitutability for Ollivier-Ricci curvature. Furthermore, extensive experiments on diverse GNN tasks demonstrate that our method achieves competitive performance with Ollivier-Ricci curvature while drastically reducing computational overhead.</p></details> |  |
| **[Non-Resolution Reasoning (NRR): A Computational Framework for Contextual Identity and Ambiguity Preservation](https://arxiv.org/abs/2512.13478v5)** | 2025-12-26 | <details><summary>Show</summary><p>Current AI systems exhibit a fundamental limitation: they resolve ambiguity prematurely. This premature semantic collapse--collapsing multiple valid interpretations into single outputs--stems from classical identity assumptions in neural architectures. We propose Non-Resolution Reasoning (NRR), treating ambiguity retention as a valid reasoning mode. NRR introduces three principles: (1) Non-Identity ($A \neq A$)--the same symbol refers to different entities across contexts; (2) Approximate Identity ($A \approx A$)--entities share partial overlap without being identical; (3) Non-Resolution--conflicting interpretations coexist without forced convergence. We formalize these through Multi-Vector Embeddings, Non-Collapsing Attention, and Contextual Identity Tracking (CIT). Functional verification via Turn 1 Entropy measurement shows NRR-lite maintains high entropy ($H = 0.63$) at ambiguous turns while standard architectures collapse early ($H = 0.10$), demonstrating that NRR preserves interpretive flexibility until context arrives. The question is not whether AI should resolve ambiguity, but when, how, and under whose control.</p></details> | <details><summary>v5: M...</summary><p>v5: Major revision to Section 5. Replaced accuracy-based OOD evaluation with entropy-based functional verification (proof-of-concept). Clarified scope as architectural demonstration rather than comparative benchmark</p></details> |
| **[HWL-HIN: A Hypergraph-Level Hypergraph Isomorphism Network as Powerful as the Hypergraph Weisfeiler-Lehman Test with Application to Higher-Order Network Robustness](https://arxiv.org/abs/2512.22014v1)** | 2025-12-26 | <details><summary>Show</summary><p>Robustness in complex systems is of significant engineering and economic importance. However, conventional attack-based a posteriori robustness assessments incur prohibitive computational overhead. Recently, deep learning methods, such as Convolutional Neural Networks (CNNs) and Graph Neural Networks (GNNs), have been widely employed as surrogates for rapid robustness prediction. Nevertheless, these methods neglect the complex higher-order correlations prevalent in real-world systems, which are naturally modeled as hypergraphs. Although Hypergraph Neural Networks (HGNNs) have been widely adopted for hypergraph learning, their topological expressive power has not yet reached the theoretical upper bound. To address this limitation, inspired by Graph Isomorphism Networks, this paper proposes a hypergraph-level Hypergraph Isomorphism Network framework. Theoretically, this approach is proven to possess an expressive power strictly equivalent to the Hypergraph Weisfeiler-Lehman test and is applied to predict hypergraph robustness. Experimental results demonstrate that while maintaining superior efficiency in training and prediction, the proposed method not only outperforms existing graph-based models but also significantly surpasses conventional HGNNs in tasks that prioritize topological structure representation.</p></details> |  |

## Diffusion
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[Exact inference via quasi-conjugacy in two-parameter Poisson-Dirichlet hidden Markov models](https://arxiv.org/abs/2512.22098v1)** | 2025-12-26 | <details><summary>Show</summary><p>We introduce a nonparametric model for time-evolving, unobserved probability distributions from discrete-time data consisting of unlabelled partitions. The latent process is a two-parameter Poisson-Dirichlet diffusion, and observations arise via exchangeable sampling. Applications include social and genetic data where only aggregate clustering summaries are observed. To address the intractable likelihood, we develop a tractable inferential framework that avoids label enumeration and direct simulation of the latent state. We exploit a duality between the diffusion and a pure-death process on partitions, together with coagulation operators that encode the effect of new data. These yield closed-form, recursive updates for forward and backward inference. We compute exact posterior distributions of the latent state at arbitrary times and predictive distributions of future or interpolated partitions. This enables online and offline inference and forecasting with full uncertainty quantification, bypassing MCMC and sequential Monte Carlo. Compared to particle filtering, our method achieves higher accuracy, lower variance, and substantial computational gains. We illustrate the methodology with synthetic experiments and a social network application, recovering interpretable patterns in time-varying heterozygosity.</p></details> |  |
| **[Yume-1.5: A Text-Controlled Interactive World Generation Model](https://arxiv.org/abs/2512.22096v1)** | 2025-12-26 | <details><summary>Show</summary><p>Recent approaches have demonstrated the promise of using diffusion models to generate interactive and explorable worlds. However, most of these methods face critical challenges such as excessively large parameter sizes, reliance on lengthy inference steps, and rapidly growing historical context, which severely limit real-time performance and lack text-controlled generation capabilities. To address these challenges, we propose \method, a novel framework designed to generate realistic, interactive, and continuous worlds from a single image or text prompt. \method achieves this through a carefully designed framework that supports keyboard-based exploration of the generated worlds. The framework comprises three core components: (1) a long-video generation framework integrating unified context compression with linear attention; (2) a real-time streaming acceleration strategy powered by bidirectional attention distillation and an enhanced text embedding scheme; (3) a text-controlled method for generating world events. We have provided the codebase in the supplementary material.</p></details> |  |
| **[Accelerating Diffusion Planners in Offline RL via Reward-Aware Consistency Trajectory Distillation](https://arxiv.org/abs/2506.07822v2)** | 2025-12-26 | <details><summary>Show</summary><p>Although diffusion models have achieved strong results in decision-making tasks, their slow inference speed remains a key limitation. While consistency models offer a potential solution, existing applications to decision-making either struggle with suboptimal demonstrations under behavior cloning or rely on complex concurrent training of multiple networks under the actor-critic framework. In this work, we propose a novel approach to consistency distillation for offline reinforcement learning that directly incorporates reward optimization into the distillation process. Our method achieves single-step sampling while generating higher-reward action trajectories through decoupled training and noise-free reward signals. Empirical evaluations on the Gym MuJoCo, FrankaKitchen, and long horizon planning benchmarks demonstrate that our approach can achieve a 9.7% improvement over previous state-of-the-art while offering up to 142x speedup over diffusion counterparts in inference time.</p></details> |  |
| **[Schwarz Information Criterion Aided Multi-Armed Bandit for Decentralized Resource Allocation in Dynamic LoRa Networks](https://arxiv.org/abs/2512.22089v1)** | 2025-12-26 | <details><summary>Show</summary><p>This paper proposes a lightweight distributed learning method for transmission parameter selection in Long Range (LoRa) networks that can adapt to dynamic communication environments. In the proposed method, each LoRa End Device (ED) employs the Upper Confidence Bound (UCB)1-tuned algorithm to select transmission parameters including channel, transmission power, and bandwidth. The transmission parameters are selected based on the acknowledgment (ACK) feedback returned from the gateway after each transmission and the corresponding transmission energy consumption. Hence, it enables devices to simultaneously optimize transmission success rate and energy efficiency in a fully distributed manner. However, although UCB1-tuned based method is effective under stationary conditions, it suffers from slow adaptation in dynamic environments due to its strong reliance on historical observations. To address this limitation, we integrate the Schwarz Information Criterion (SIC) to our proposed method. SIC is adopted because it enables low-cost detection of changes in the communication environment, making it suitable for implementation on resource-constrained LoRa EDs. When a change is detected by SIC, the learning history of UCB1-tuned is reset, allowing rapid re-learning under the new conditions. Experimental results using real LoRa devices demonstrate that the proposed method achieves superior transmission success rate, energy efficiency, and adaptability compared with the conventional UCB1-tuned algorithm without SIC.</p></details> | 6 pages, 5 figures |
| **[Random state comonads encode cellular automata evaluation](https://arxiv.org/abs/2512.22067v1)** | 2025-12-26 | <details><summary>Show</summary><p>Cellular automata (CA) are quintessential ALife and ubiquitous in many studies of collective behaviour and emergence, from morphogenesis to social dynamics and even brain modelling. Recently, there has been an increased interest in formalising CA, theoretically through category theory and practically in terms of a functional programming paradigm. Unfortunately, these remain either in the realm of simple implementations lacking important practical features, or too abstract and conceptually inaccessible to be useful to the ALife community at large. In this paper, we present a brief and accessible introduction to a category-theoretical model of CA computation through a practical implementation in Haskell. We instantiate arrays as comonads with state and random generators, allowing stochastic behaviour not currently supported in other known implementations. We also emphasise the importance of functional implementations for complex systems: thanks to the Curry-Howard-Lambek isomorphism, functional programs facilitate a mapping between simulation, system rules or semantics, and categorical descriptions, which may advance our understanding and development of generalised theories of emergent behaviour. Using this implementation, we show case studies of four famous CA models: first Wolfram's CA in 1D, then Conway's game of life, Greenberg-Hasings excitable cells, and the stochastic Forest Fire model in 2D, and present directions for an extension to N dimensions. Finally, we suggest that the comonadic model can encode arbitrary topologies and propose future directions for a comonadic network.</p></details> | 5 pages, 5 figures |
| **[StreamAvatar: Streaming Diffusion Models for Real-Time Interactive Human Avatars](https://arxiv.org/abs/2512.22065v1)** | 2025-12-26 | <details><summary>Show</summary><p>Real-time, streaming interactive avatars represent a critical yet challenging goal in digital human research. Although diffusion-based human avatar generation methods achieve remarkable success, their non-causal architecture and high computational costs make them unsuitable for streaming. Moreover, existing interactive approaches are typically limited to head-and-shoulder region, limiting their ability to produce gestures and body motions. To address these challenges, we propose a two-stage autoregressive adaptation and acceleration framework that applies autoregressive distillation and adversarial refinement to adapt a high-fidelity human video diffusion model for real-time, interactive streaming. To ensure long-term stability and consistency, we introduce three key components: a Reference Sink, a Reference-Anchored Positional Re-encoding (RAPR) strategy, and a Consistency-Aware Discriminator. Building on this framework, we develop a one-shot, interactive, human avatar model capable of generating both natural talking and listening behaviors with coherent gestures. Extensive experiments demonstrate that our method achieves state-of-the-art performance, surpassing existing approaches in generation quality, real-time efficiency, and interaction naturalness. Project page: https://streamavatar.github.io .</p></details> | <details><summary>Proje...</summary><p>Project page: https://streamavatar.github.io</p></details> |
| **[Real-Time Streamable Generative Speech Restoration with Flow Matching](https://arxiv.org/abs/2512.19442v2)** | 2025-12-26 | <details><summary>Show</summary><p>Diffusion-based generative models have greatly impacted the speech processing field in recent years, exhibiting high speech naturalness and spawning a new research direction. Their application in real-time communication is, however, still lagging behind due to their computation-heavy nature involving multiple calls of large DNNs. Here, we present Stream$.$FM, a frame-causal flow-based generative model with an algorithmic latency of 32 milliseconds (ms) and a total latency of 48 ms, paving the way for generative speech processing in real-time communication. We propose a buffered streaming inference scheme and an optimized DNN architecture, show how learned few-step numerical solvers can boost output quality at a fixed compute budget, explore model weight compression to find favorable points along a compute/quality tradeoff, and contribute a model variant with 24 ms total latency for the speech enhancement task. Our work looks beyond theoretical latencies, showing that high-quality streaming generative speech processing can be realized on consumer GPUs available today. Stream$.$FM can solve a variety of speech processing tasks in a streaming fashion: speech enhancement, dereverberation, codec post-filtering, bandwidth extension, STFT phase retrieval, and Mel vocoding. As we verify through comprehensive evaluations and a MUSHRA listening test, Stream$.$FM establishes a state-of-the-art for generative streaming speech restoration, exhibits only a reasonable reduction in quality compared to a non-streaming variant, and outperforms our recent work (Diffusion Buffer) on generative streaming speech enhancement while operating at a lower latency.</p></details> | <details><summary>This ...</summary><p>This work has been submitted to the IEEE for possible publication</p></details> |
| **[M2RU: Memristive Minion Recurrent Unit for On-Chip Continual Learning at the Edge](https://arxiv.org/abs/2512.17299v2)** | 2025-12-26 | <details><summary>Show</summary><p>Continual learning on edge platforms remains challenging because recurrent networks depend on energy-intensive training procedures and frequent data movement that are impractical for embedded deployments. This work introduces M2RU, a mixed-signal architecture that implements the minion recurrent unit for efficient temporal processing with on-chip continual learning. The architecture integrates weighted-bit streaming, which enables multi-bit digital inputs to be processed in crossbars without high-resolution conversion, and an experience replay mechanism that stabilizes learning under domain shifts. M2RU achieves 15 GOPS at 48.62 mW, corresponding to 312 GOPS per watt, and maintains accuracy within 5 percent of software baselines on sequential MNIST and CIFAR-10 tasks. Compared with a CMOS digital design, the accelerator provides 29X improvement in energy efficiency. Device-aware analysis shows an expected operational lifetime of 12.2 years under continual learning workloads. These results establish M2RU as a scalable and energy-efficient platform for real-time adaptation in edge-level temporal intelligence.</p></details> |  |
| **[Backdoor Attacks on Prompt-Driven Video Segmentation Foundation Models](https://arxiv.org/abs/2512.22046v1)** | 2025-12-26 | <details><summary>Show</summary><p>Prompt-driven Video Segmentation Foundation Models (VSFMs) such as SAM2 are increasingly deployed in applications like autonomous driving and digital pathology, raising concerns about backdoor threats. Surprisingly, we find that directly transferring classic backdoor attacks (e.g., BadNet) to VSFMs is almost ineffective, with ASR below 5\%. To understand this, we study encoder gradients and attention maps and observe that conventional training keeps gradients for clean and triggered samples largely aligned, while attention still focuses on the true object, preventing the encoder from learning a distinct trigger-related representation. To address this challenge, we propose BadVSFM, the first backdoor framework tailored to prompt-driven VSFMs. BadVSFM uses a two-stage strategy: (1) steer the image encoder so triggered frames map to a designated target embedding while clean frames remain aligned with a clean reference encoder; (2) train the mask decoder so that, across prompt types, triggered frame-prompt pairs produce a shared target mask, while clean outputs stay close to a reference decoder. Extensive experiments on two datasets and five VSFMs show that BadVSFM achieves strong, controllable backdoor effects under diverse triggers and prompts while preserving clean segmentation quality. Ablations over losses, stages, targets, trigger settings, and poisoning rates demonstrate robustness to reasonable hyperparameter changes and confirm the necessity of the two-stage design. Finally, gradient-conflict analysis and attention visualizations show that BadVSFM separates triggered and clean representations and shifts attention to trigger regions, while four representative defenses remain largely ineffective, revealing an underexplored vulnerability in current VSFMs.</p></details> |  |

## Object Counting
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[Schwarz Information Criterion Aided Multi-Armed Bandit for Decentralized Resource Allocation in Dynamic LoRa Networks](https://arxiv.org/abs/2512.22089v1)** | 2025-12-26 | <details><summary>Show</summary><p>This paper proposes a lightweight distributed learning method for transmission parameter selection in Long Range (LoRa) networks that can adapt to dynamic communication environments. In the proposed method, each LoRa End Device (ED) employs the Upper Confidence Bound (UCB)1-tuned algorithm to select transmission parameters including channel, transmission power, and bandwidth. The transmission parameters are selected based on the acknowledgment (ACK) feedback returned from the gateway after each transmission and the corresponding transmission energy consumption. Hence, it enables devices to simultaneously optimize transmission success rate and energy efficiency in a fully distributed manner. However, although UCB1-tuned based method is effective under stationary conditions, it suffers from slow adaptation in dynamic environments due to its strong reliance on historical observations. To address this limitation, we integrate the Schwarz Information Criterion (SIC) to our proposed method. SIC is adopted because it enables low-cost detection of changes in the communication environment, making it suitable for implementation on resource-constrained LoRa EDs. When a change is detected by SIC, the learning history of UCB1-tuned is reset, allowing rapid re-learning under the new conditions. Experimental results using real LoRa devices demonstrate that the proposed method achieves superior transmission success rate, energy efficiency, and adaptability compared with the conventional UCB1-tuned algorithm without SIC.</p></details> | 6 pages, 5 figures |
| **[Random state comonads encode cellular automata evaluation](https://arxiv.org/abs/2512.22067v1)** | 2025-12-26 | <details><summary>Show</summary><p>Cellular automata (CA) are quintessential ALife and ubiquitous in many studies of collective behaviour and emergence, from morphogenesis to social dynamics and even brain modelling. Recently, there has been an increased interest in formalising CA, theoretically through category theory and practically in terms of a functional programming paradigm. Unfortunately, these remain either in the realm of simple implementations lacking important practical features, or too abstract and conceptually inaccessible to be useful to the ALife community at large. In this paper, we present a brief and accessible introduction to a category-theoretical model of CA computation through a practical implementation in Haskell. We instantiate arrays as comonads with state and random generators, allowing stochastic behaviour not currently supported in other known implementations. We also emphasise the importance of functional implementations for complex systems: thanks to the Curry-Howard-Lambek isomorphism, functional programs facilitate a mapping between simulation, system rules or semantics, and categorical descriptions, which may advance our understanding and development of generalised theories of emergent behaviour. Using this implementation, we show case studies of four famous CA models: first Wolfram's CA in 1D, then Conway's game of life, Greenberg-Hasings excitable cells, and the stochastic Forest Fire model in 2D, and present directions for an extension to N dimensions. Finally, we suggest that the comonadic model can encode arbitrary topologies and propose future directions for a comonadic network.</p></details> | 5 pages, 5 figures |
| **[M2RU: Memristive Minion Recurrent Unit for On-Chip Continual Learning at the Edge](https://arxiv.org/abs/2512.17299v2)** | 2025-12-26 | <details><summary>Show</summary><p>Continual learning on edge platforms remains challenging because recurrent networks depend on energy-intensive training procedures and frequent data movement that are impractical for embedded deployments. This work introduces M2RU, a mixed-signal architecture that implements the minion recurrent unit for efficient temporal processing with on-chip continual learning. The architecture integrates weighted-bit streaming, which enables multi-bit digital inputs to be processed in crossbars without high-resolution conversion, and an experience replay mechanism that stabilizes learning under domain shifts. M2RU achieves 15 GOPS at 48.62 mW, corresponding to 312 GOPS per watt, and maintains accuracy within 5 percent of software baselines on sequential MNIST and CIFAR-10 tasks. Compared with a CMOS digital design, the accelerator provides 29X improvement in energy efficiency. Device-aware analysis shows an expected operational lifetime of 12.2 years under continual learning workloads. These results establish M2RU as a scalable and energy-efficient platform for real-time adaptation in edge-level temporal intelligence.</p></details> |  |
| **[Backdoor Attacks on Prompt-Driven Video Segmentation Foundation Models](https://arxiv.org/abs/2512.22046v1)** | 2025-12-26 | <details><summary>Show</summary><p>Prompt-driven Video Segmentation Foundation Models (VSFMs) such as SAM2 are increasingly deployed in applications like autonomous driving and digital pathology, raising concerns about backdoor threats. Surprisingly, we find that directly transferring classic backdoor attacks (e.g., BadNet) to VSFMs is almost ineffective, with ASR below 5\%. To understand this, we study encoder gradients and attention maps and observe that conventional training keeps gradients for clean and triggered samples largely aligned, while attention still focuses on the true object, preventing the encoder from learning a distinct trigger-related representation. To address this challenge, we propose BadVSFM, the first backdoor framework tailored to prompt-driven VSFMs. BadVSFM uses a two-stage strategy: (1) steer the image encoder so triggered frames map to a designated target embedding while clean frames remain aligned with a clean reference encoder; (2) train the mask decoder so that, across prompt types, triggered frame-prompt pairs produce a shared target mask, while clean outputs stay close to a reference decoder. Extensive experiments on two datasets and five VSFMs show that BadVSFM achieves strong, controllable backdoor effects under diverse triggers and prompts while preserving clean segmentation quality. Ablations over losses, stages, targets, trigger settings, and poisoning rates demonstrate robustness to reasonable hyperparameter changes and confirm the necessity of the two-stage design. Finally, gradient-conflict analysis and attention visualizations show that BadVSFM separates triggered and clean representations and shifts attention to trigger regions, while four representative defenses remain largely ineffective, revealing an underexplored vulnerability in current VSFMs.</p></details> |  |
| **[Direction Finding with Sparse Arrays Based on Variable Window Size Spatial Smoothing](https://arxiv.org/abs/2512.22024v1)** | 2025-12-26 | <details><summary>Show</summary><p>In this work, we introduce a variable window size (VWS) spatial smoothing framework that enhances coarray-based direction of arrival (DOA) estimation for sparse linear arrays. By compressing the smoothing aperture, the proposed VWS Coarray MUSIC (VWS-CA-MUSIC) and VWS Coarray root-MUSIC (VWS-CA-rMUSIC) algorithms replace part of the perturbed rank-one outer products in the smoothed coarray data with unperturbed low-rank additional terms, increasing the separation between signal and noise subspaces, while preserving the signal subspace span. We also derive the bounds that guarantees identifiability, by limiting the values that can be assumed by the compression parameter. Simulations with sparse geometries reveal significant performance improvements and complexity savings relative to the fixed-window coarray MUSIC method.</p></details> | 2 figures, 5 pages |
| **[Non-Resolution Reasoning (NRR): A Computational Framework for Contextual Identity and Ambiguity Preservation](https://arxiv.org/abs/2512.13478v5)** | 2025-12-26 | <details><summary>Show</summary><p>Current AI systems exhibit a fundamental limitation: they resolve ambiguity prematurely. This premature semantic collapse--collapsing multiple valid interpretations into single outputs--stems from classical identity assumptions in neural architectures. We propose Non-Resolution Reasoning (NRR), treating ambiguity retention as a valid reasoning mode. NRR introduces three principles: (1) Non-Identity ($A \neq A$)--the same symbol refers to different entities across contexts; (2) Approximate Identity ($A \approx A$)--entities share partial overlap without being identical; (3) Non-Resolution--conflicting interpretations coexist without forced convergence. We formalize these through Multi-Vector Embeddings, Non-Collapsing Attention, and Contextual Identity Tracking (CIT). Functional verification via Turn 1 Entropy measurement shows NRR-lite maintains high entropy ($H = 0.63$) at ambiguous turns while standard architectures collapse early ($H = 0.10$), demonstrating that NRR preserves interpretive flexibility until context arrives. The question is not whether AI should resolve ambiguity, but when, how, and under whose control.</p></details> | <details><summary>v5: M...</summary><p>v5: Major revision to Section 5. Replaced accuracy-based OOD evaluation with entropy-based functional verification (proof-of-concept). Clarified scope as architectural demonstration rather than comparative benchmark</p></details> |
| **[Research on a hybrid LSTM-CNN-Attention model for text-based web content classification](https://arxiv.org/abs/2512.18475v2)** | 2025-12-26 | <details><summary>Show</summary><p>This study presents a hybrid deep learning architecture that integrates LSTM, CNN, and an Attention mechanism to enhance the classification of web content based on text. Pretrained GloVe embeddings are used to represent words as dense vectors that preserve semantic similarity. The CNN layer extracts local n-gram patterns and lexical features, while the LSTM layer models long-range dependencies and sequential structure. The integrated Attention mechanism enables the model to focus selectively on the most informative parts of the input sequence. A 5-fold cross-validation setup was used to assess the robustness and generalizability of the proposed solution. Experimental results show that the hybrid LSTM-CNN-Attention model achieved outstanding performance, with an accuracy of 0.98, precision of 0.94, recall of 0.92, and F1-score of 0.93. These results surpass the performance of baseline models based solely on CNNs, LSTMs, or transformer-based classifiers such as BERT. The combination of neural network components enabled the model to effectively capture both fine-grained text structures and broader semantic context. Furthermore, the use of GloVe embeddings provided an efficient and effective representation of textual data, making the model suitable for integration into systems with real-time or near-real-time requirements. The proposed hybrid architecture demonstrates high effectiveness in text-based web content classification, particularly in tasks requiring both syntactic feature extraction and semantic interpretation. By combining presented mechanisms, the model addresses the limitations of individual architectures and achieves improved generalization. These findings support the broader use of hybrid deep learning approaches in NLP applications, especially where complex, unstructured textual data must be processed and classified with high reliability.</p></details> | <details><summary>10 pa...</summary><p>10 pages, 5 figures, 2 tables. Published by Radio Electronics Computer Science Control 2025</p></details> |
| **[Super-LIO: A Robust and Efficient LiDAR-Inertial Odometry System with a Compact Mapping Strategy](https://arxiv.org/abs/2509.05723v2)** | 2025-12-26 | <details><summary>Show</summary><p>LiDAR-Inertial Odometry (LIO) is a foundational technique for autonomous systems, yet its deployment on resource-constrained platforms remains challenging due to computational and memory limitations. We propose Super-LIO, a robust LIO system that demands both high performance and accuracy, ideal for applications such as aerial robots and mobile autonomous systems. At the core of Super-LIO is a compact octo-voxel-based map structure, termed OctVox, that limits each voxel to eight fused subvoxels, enabling strict point density control and incremental denoising during map updates. This design enables a simple yet efficient and accurate map structure, which can be easily integrated into existing LIO frameworks. Additionally, Super-LIO designs a heuristic-guided KNN strategy (HKNN) that accelerates the correspondence search by leveraging spatial locality, further reducing runtime overhead. We evaluated the proposed system using four publicly available datasets and several self-collected datasets, totaling more than 30 sequences. Extensive testing on both X86 and ARM platforms confirms that Super-LIO offers superior efficiency and robustness, while maintaining competitive accuracy. Super-LIO processes each frame approximately 73% faster than SOTA, while consuming less CPU resources. The system is fully open-source and plug-and-play compatible with a wide range of LiDAR sensors and platforms. The implementation is available at: https://github.com/Liansheng-Wang/Super-LIO.git</p></details> | 8 pages, 5 figures |

## Image Caption
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[Schwarz Information Criterion Aided Multi-Armed Bandit for Decentralized Resource Allocation in Dynamic LoRa Networks](https://arxiv.org/abs/2512.22089v1)** | 2025-12-26 | <details><summary>Show</summary><p>This paper proposes a lightweight distributed learning method for transmission parameter selection in Long Range (LoRa) networks that can adapt to dynamic communication environments. In the proposed method, each LoRa End Device (ED) employs the Upper Confidence Bound (UCB)1-tuned algorithm to select transmission parameters including channel, transmission power, and bandwidth. The transmission parameters are selected based on the acknowledgment (ACK) feedback returned from the gateway after each transmission and the corresponding transmission energy consumption. Hence, it enables devices to simultaneously optimize transmission success rate and energy efficiency in a fully distributed manner. However, although UCB1-tuned based method is effective under stationary conditions, it suffers from slow adaptation in dynamic environments due to its strong reliance on historical observations. To address this limitation, we integrate the Schwarz Information Criterion (SIC) to our proposed method. SIC is adopted because it enables low-cost detection of changes in the communication environment, making it suitable for implementation on resource-constrained LoRa EDs. When a change is detected by SIC, the learning history of UCB1-tuned is reset, allowing rapid re-learning under the new conditions. Experimental results using real LoRa devices demonstrate that the proposed method achieves superior transmission success rate, energy efficiency, and adaptability compared with the conventional UCB1-tuned algorithm without SIC.</p></details> | 6 pages, 5 figures |
| **[Random state comonads encode cellular automata evaluation](https://arxiv.org/abs/2512.22067v1)** | 2025-12-26 | <details><summary>Show</summary><p>Cellular automata (CA) are quintessential ALife and ubiquitous in many studies of collective behaviour and emergence, from morphogenesis to social dynamics and even brain modelling. Recently, there has been an increased interest in formalising CA, theoretically through category theory and practically in terms of a functional programming paradigm. Unfortunately, these remain either in the realm of simple implementations lacking important practical features, or too abstract and conceptually inaccessible to be useful to the ALife community at large. In this paper, we present a brief and accessible introduction to a category-theoretical model of CA computation through a practical implementation in Haskell. We instantiate arrays as comonads with state and random generators, allowing stochastic behaviour not currently supported in other known implementations. We also emphasise the importance of functional implementations for complex systems: thanks to the Curry-Howard-Lambek isomorphism, functional programs facilitate a mapping between simulation, system rules or semantics, and categorical descriptions, which may advance our understanding and development of generalised theories of emergent behaviour. Using this implementation, we show case studies of four famous CA models: first Wolfram's CA in 1D, then Conway's game of life, Greenberg-Hasings excitable cells, and the stochastic Forest Fire model in 2D, and present directions for an extension to N dimensions. Finally, we suggest that the comonadic model can encode arbitrary topologies and propose future directions for a comonadic network.</p></details> | 5 pages, 5 figures |
| **[M2RU: Memristive Minion Recurrent Unit for On-Chip Continual Learning at the Edge](https://arxiv.org/abs/2512.17299v2)** | 2025-12-26 | <details><summary>Show</summary><p>Continual learning on edge platforms remains challenging because recurrent networks depend on energy-intensive training procedures and frequent data movement that are impractical for embedded deployments. This work introduces M2RU, a mixed-signal architecture that implements the minion recurrent unit for efficient temporal processing with on-chip continual learning. The architecture integrates weighted-bit streaming, which enables multi-bit digital inputs to be processed in crossbars without high-resolution conversion, and an experience replay mechanism that stabilizes learning under domain shifts. M2RU achieves 15 GOPS at 48.62 mW, corresponding to 312 GOPS per watt, and maintains accuracy within 5 percent of software baselines on sequential MNIST and CIFAR-10 tasks. Compared with a CMOS digital design, the accelerator provides 29X improvement in energy efficiency. Device-aware analysis shows an expected operational lifetime of 12.2 years under continual learning workloads. These results establish M2RU as a scalable and energy-efficient platform for real-time adaptation in edge-level temporal intelligence.</p></details> |  |
| **[Backdoor Attacks on Prompt-Driven Video Segmentation Foundation Models](https://arxiv.org/abs/2512.22046v1)** | 2025-12-26 | <details><summary>Show</summary><p>Prompt-driven Video Segmentation Foundation Models (VSFMs) such as SAM2 are increasingly deployed in applications like autonomous driving and digital pathology, raising concerns about backdoor threats. Surprisingly, we find that directly transferring classic backdoor attacks (e.g., BadNet) to VSFMs is almost ineffective, with ASR below 5\%. To understand this, we study encoder gradients and attention maps and observe that conventional training keeps gradients for clean and triggered samples largely aligned, while attention still focuses on the true object, preventing the encoder from learning a distinct trigger-related representation. To address this challenge, we propose BadVSFM, the first backdoor framework tailored to prompt-driven VSFMs. BadVSFM uses a two-stage strategy: (1) steer the image encoder so triggered frames map to a designated target embedding while clean frames remain aligned with a clean reference encoder; (2) train the mask decoder so that, across prompt types, triggered frame-prompt pairs produce a shared target mask, while clean outputs stay close to a reference decoder. Extensive experiments on two datasets and five VSFMs show that BadVSFM achieves strong, controllable backdoor effects under diverse triggers and prompts while preserving clean segmentation quality. Ablations over losses, stages, targets, trigger settings, and poisoning rates demonstrate robustness to reasonable hyperparameter changes and confirm the necessity of the two-stage design. Finally, gradient-conflict analysis and attention visualizations show that BadVSFM separates triggered and clean representations and shifts attention to trigger regions, while four representative defenses remain largely ineffective, revealing an underexplored vulnerability in current VSFMs.</p></details> |  |
| **[Direction Finding with Sparse Arrays Based on Variable Window Size Spatial Smoothing](https://arxiv.org/abs/2512.22024v1)** | 2025-12-26 | <details><summary>Show</summary><p>In this work, we introduce a variable window size (VWS) spatial smoothing framework that enhances coarray-based direction of arrival (DOA) estimation for sparse linear arrays. By compressing the smoothing aperture, the proposed VWS Coarray MUSIC (VWS-CA-MUSIC) and VWS Coarray root-MUSIC (VWS-CA-rMUSIC) algorithms replace part of the perturbed rank-one outer products in the smoothed coarray data with unperturbed low-rank additional terms, increasing the separation between signal and noise subspaces, while preserving the signal subspace span. We also derive the bounds that guarantees identifiability, by limiting the values that can be assumed by the compression parameter. Simulations with sparse geometries reveal significant performance improvements and complexity savings relative to the fixed-window coarray MUSIC method.</p></details> | 2 figures, 5 pages |
| **[Non-Resolution Reasoning (NRR): A Computational Framework for Contextual Identity and Ambiguity Preservation](https://arxiv.org/abs/2512.13478v5)** | 2025-12-26 | <details><summary>Show</summary><p>Current AI systems exhibit a fundamental limitation: they resolve ambiguity prematurely. This premature semantic collapse--collapsing multiple valid interpretations into single outputs--stems from classical identity assumptions in neural architectures. We propose Non-Resolution Reasoning (NRR), treating ambiguity retention as a valid reasoning mode. NRR introduces three principles: (1) Non-Identity ($A \neq A$)--the same symbol refers to different entities across contexts; (2) Approximate Identity ($A \approx A$)--entities share partial overlap without being identical; (3) Non-Resolution--conflicting interpretations coexist without forced convergence. We formalize these through Multi-Vector Embeddings, Non-Collapsing Attention, and Contextual Identity Tracking (CIT). Functional verification via Turn 1 Entropy measurement shows NRR-lite maintains high entropy ($H = 0.63$) at ambiguous turns while standard architectures collapse early ($H = 0.10$), demonstrating that NRR preserves interpretive flexibility until context arrives. The question is not whether AI should resolve ambiguity, but when, how, and under whose control.</p></details> | <details><summary>v5: M...</summary><p>v5: Major revision to Section 5. Replaced accuracy-based OOD evaluation with entropy-based functional verification (proof-of-concept). Clarified scope as architectural demonstration rather than comparative benchmark</p></details> |
| **[Research on a hybrid LSTM-CNN-Attention model for text-based web content classification](https://arxiv.org/abs/2512.18475v2)** | 2025-12-26 | <details><summary>Show</summary><p>This study presents a hybrid deep learning architecture that integrates LSTM, CNN, and an Attention mechanism to enhance the classification of web content based on text. Pretrained GloVe embeddings are used to represent words as dense vectors that preserve semantic similarity. The CNN layer extracts local n-gram patterns and lexical features, while the LSTM layer models long-range dependencies and sequential structure. The integrated Attention mechanism enables the model to focus selectively on the most informative parts of the input sequence. A 5-fold cross-validation setup was used to assess the robustness and generalizability of the proposed solution. Experimental results show that the hybrid LSTM-CNN-Attention model achieved outstanding performance, with an accuracy of 0.98, precision of 0.94, recall of 0.92, and F1-score of 0.93. These results surpass the performance of baseline models based solely on CNNs, LSTMs, or transformer-based classifiers such as BERT. The combination of neural network components enabled the model to effectively capture both fine-grained text structures and broader semantic context. Furthermore, the use of GloVe embeddings provided an efficient and effective representation of textual data, making the model suitable for integration into systems with real-time or near-real-time requirements. The proposed hybrid architecture demonstrates high effectiveness in text-based web content classification, particularly in tasks requiring both syntactic feature extraction and semantic interpretation. By combining presented mechanisms, the model addresses the limitations of individual architectures and achieves improved generalization. These findings support the broader use of hybrid deep learning approaches in NLP applications, especially where complex, unstructured textual data must be processed and classified with high reliability.</p></details> | <details><summary>10 pa...</summary><p>10 pages, 5 figures, 2 tables. Published by Radio Electronics Computer Science Control 2025</p></details> |
| **[Super-LIO: A Robust and Efficient LiDAR-Inertial Odometry System with a Compact Mapping Strategy](https://arxiv.org/abs/2509.05723v2)** | 2025-12-26 | <details><summary>Show</summary><p>LiDAR-Inertial Odometry (LIO) is a foundational technique for autonomous systems, yet its deployment on resource-constrained platforms remains challenging due to computational and memory limitations. We propose Super-LIO, a robust LIO system that demands both high performance and accuracy, ideal for applications such as aerial robots and mobile autonomous systems. At the core of Super-LIO is a compact octo-voxel-based map structure, termed OctVox, that limits each voxel to eight fused subvoxels, enabling strict point density control and incremental denoising during map updates. This design enables a simple yet efficient and accurate map structure, which can be easily integrated into existing LIO frameworks. Additionally, Super-LIO designs a heuristic-guided KNN strategy (HKNN) that accelerates the correspondence search by leveraging spatial locality, further reducing runtime overhead. We evaluated the proposed system using four publicly available datasets and several self-collected datasets, totaling more than 30 sequences. Extensive testing on both X86 and ARM platforms confirms that Super-LIO offers superior efficiency and robustness, while maintaining competitive accuracy. Super-LIO processes each frame approximately 73% faster than SOTA, while consuming less CPU resources. The system is fully open-source and plug-and-play compatible with a wide range of LiDAR sensors and platforms. The implementation is available at: https://github.com/Liansheng-Wang/Super-LIO.git</p></details> | 8 pages, 5 figures |

## Describe
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[Abstraction of Trusted Execution Environments as the Missing Layer for Broad Confidential Computing Adoption: A Systematization of Knowledge](https://arxiv.org/abs/2512.22090v1)** | 2025-12-26 | <details><summary>Show</summary><p>Trusted Execution Environments (TEEs) protect sensitive code and data from the operating system, hypervisor, or other untrusted software. Different solutions exist, each proposing different features. Abstraction layers aim to unify the ecosystem, allowing application developers and system administrators to leverage confidential computing as broadly and efficiently as possible. We start with an overview of representative available TEE technologies. We describe and summarize each TEE ecosystem, classifying them in different categories depending on their main design choices. Then, we propose a systematization of knowledge focusing on different abstraction layers around each design choice. We describe the underlying technologies of each design, as well as the inner workings and features of each abstraction layer. Our study reveals opportunities for improving existing abstraction layer solutions. It also highlights WebAssembly, a promising approach that supports the largest set of features. We close with a discussion on future directions for research, such as how future abstraction layers may evolve and integrate with the confidential computing ecosystem.</p></details> |  |
| **[Schwarz Information Criterion Aided Multi-Armed Bandit for Decentralized Resource Allocation in Dynamic LoRa Networks](https://arxiv.org/abs/2512.22089v1)** | 2025-12-26 | <details><summary>Show</summary><p>This paper proposes a lightweight distributed learning method for transmission parameter selection in Long Range (LoRa) networks that can adapt to dynamic communication environments. In the proposed method, each LoRa End Device (ED) employs the Upper Confidence Bound (UCB)1-tuned algorithm to select transmission parameters including channel, transmission power, and bandwidth. The transmission parameters are selected based on the acknowledgment (ACK) feedback returned from the gateway after each transmission and the corresponding transmission energy consumption. Hence, it enables devices to simultaneously optimize transmission success rate and energy efficiency in a fully distributed manner. However, although UCB1-tuned based method is effective under stationary conditions, it suffers from slow adaptation in dynamic environments due to its strong reliance on historical observations. To address this limitation, we integrate the Schwarz Information Criterion (SIC) to our proposed method. SIC is adopted because it enables low-cost detection of changes in the communication environment, making it suitable for implementation on resource-constrained LoRa EDs. When a change is detected by SIC, the learning history of UCB1-tuned is reset, allowing rapid re-learning under the new conditions. Experimental results using real LoRa devices demonstrate that the proposed method achieves superior transmission success rate, energy efficiency, and adaptability compared with the conventional UCB1-tuned algorithm without SIC.</p></details> | 6 pages, 5 figures |
| **[fMRI-LM: Towards a Universal Foundation Model for Language-Aligned fMRI Understanding](https://arxiv.org/abs/2511.21760v2)** | 2025-12-26 | <details><summary>Show</summary><p>Recent advances in multimodal large language models (LLMs) have enabled unified reasoning across images, audio, and video, but extending such capability to brain imaging remains largely unexplored. Bridging this gap is essential to link neural activity with semantic cognition and to develop cross-modal brain representations. To this end, we present fMRI-LM, a foundational model that bridges functional MRI (fMRI) and language through a three-stage framework. In Stage 1, we learn a neural tokenizer that maps fMRI into discrete tokens embedded in a language-consistent space. In Stage 2, a pretrained LLM is adapted to jointly model fMRI tokens and text, treating brain activity as a sequence that can be temporally predicted and linguistically described. To overcome the lack of natural fMRI-text pairs, we construct a large descriptive corpus that translates diverse imaging-based features into structured textual descriptors, capturing the low-level organization of fMRI signals. In Stage 3, we perform multi-task, multi-paradigm instruction tuning to endow fMRI-LM with high-level semantic understanding, supporting diverse downstream applications. Across various benchmarks, fMRI-LM achieves strong zero-shot and few-shot performance, and adapts efficiently with parameter-efficient tuning (LoRA), establishing a scalable pathway toward a language-aligned, universal model for structural and semantic understanding of fMRI.</p></details> | <details><summary>Code ...</summary><p>Code are available: https://github.com/yuxiangwei0808/fMRI-LM</p></details> |
| **[Random state comonads encode cellular automata evaluation](https://arxiv.org/abs/2512.22067v1)** | 2025-12-26 | <details><summary>Show</summary><p>Cellular automata (CA) are quintessential ALife and ubiquitous in many studies of collective behaviour and emergence, from morphogenesis to social dynamics and even brain modelling. Recently, there has been an increased interest in formalising CA, theoretically through category theory and practically in terms of a functional programming paradigm. Unfortunately, these remain either in the realm of simple implementations lacking important practical features, or too abstract and conceptually inaccessible to be useful to the ALife community at large. In this paper, we present a brief and accessible introduction to a category-theoretical model of CA computation through a practical implementation in Haskell. We instantiate arrays as comonads with state and random generators, allowing stochastic behaviour not currently supported in other known implementations. We also emphasise the importance of functional implementations for complex systems: thanks to the Curry-Howard-Lambek isomorphism, functional programs facilitate a mapping between simulation, system rules or semantics, and categorical descriptions, which may advance our understanding and development of generalised theories of emergent behaviour. Using this implementation, we show case studies of four famous CA models: first Wolfram's CA in 1D, then Conway's game of life, Greenberg-Hasings excitable cells, and the stochastic Forest Fire model in 2D, and present directions for an extension to N dimensions. Finally, we suggest that the comonadic model can encode arbitrary topologies and propose future directions for a comonadic network.</p></details> | 5 pages, 5 figures |
| **[M2RU: Memristive Minion Recurrent Unit for On-Chip Continual Learning at the Edge](https://arxiv.org/abs/2512.17299v2)** | 2025-12-26 | <details><summary>Show</summary><p>Continual learning on edge platforms remains challenging because recurrent networks depend on energy-intensive training procedures and frequent data movement that are impractical for embedded deployments. This work introduces M2RU, a mixed-signal architecture that implements the minion recurrent unit for efficient temporal processing with on-chip continual learning. The architecture integrates weighted-bit streaming, which enables multi-bit digital inputs to be processed in crossbars without high-resolution conversion, and an experience replay mechanism that stabilizes learning under domain shifts. M2RU achieves 15 GOPS at 48.62 mW, corresponding to 312 GOPS per watt, and maintains accuracy within 5 percent of software baselines on sequential MNIST and CIFAR-10 tasks. Compared with a CMOS digital design, the accelerator provides 29X improvement in energy efficiency. Device-aware analysis shows an expected operational lifetime of 12.2 years under continual learning workloads. These results establish M2RU as a scalable and energy-efficient platform for real-time adaptation in edge-level temporal intelligence.</p></details> |  |
| **[Backdoor Attacks on Prompt-Driven Video Segmentation Foundation Models](https://arxiv.org/abs/2512.22046v1)** | 2025-12-26 | <details><summary>Show</summary><p>Prompt-driven Video Segmentation Foundation Models (VSFMs) such as SAM2 are increasingly deployed in applications like autonomous driving and digital pathology, raising concerns about backdoor threats. Surprisingly, we find that directly transferring classic backdoor attacks (e.g., BadNet) to VSFMs is almost ineffective, with ASR below 5\%. To understand this, we study encoder gradients and attention maps and observe that conventional training keeps gradients for clean and triggered samples largely aligned, while attention still focuses on the true object, preventing the encoder from learning a distinct trigger-related representation. To address this challenge, we propose BadVSFM, the first backdoor framework tailored to prompt-driven VSFMs. BadVSFM uses a two-stage strategy: (1) steer the image encoder so triggered frames map to a designated target embedding while clean frames remain aligned with a clean reference encoder; (2) train the mask decoder so that, across prompt types, triggered frame-prompt pairs produce a shared target mask, while clean outputs stay close to a reference decoder. Extensive experiments on two datasets and five VSFMs show that BadVSFM achieves strong, controllable backdoor effects under diverse triggers and prompts while preserving clean segmentation quality. Ablations over losses, stages, targets, trigger settings, and poisoning rates demonstrate robustness to reasonable hyperparameter changes and confirm the necessity of the two-stage design. Finally, gradient-conflict analysis and attention visualizations show that BadVSFM separates triggered and clean representations and shifts attention to trigger regions, while four representative defenses remain largely ineffective, revealing an underexplored vulnerability in current VSFMs.</p></details> |  |

## Light Weight
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[Schwarz Information Criterion Aided Multi-Armed Bandit for Decentralized Resource Allocation in Dynamic LoRa Networks](https://arxiv.org/abs/2512.22089v1)** | 2025-12-26 | <details><summary>Show</summary><p>This paper proposes a lightweight distributed learning method for transmission parameter selection in Long Range (LoRa) networks that can adapt to dynamic communication environments. In the proposed method, each LoRa End Device (ED) employs the Upper Confidence Bound (UCB)1-tuned algorithm to select transmission parameters including channel, transmission power, and bandwidth. The transmission parameters are selected based on the acknowledgment (ACK) feedback returned from the gateway after each transmission and the corresponding transmission energy consumption. Hence, it enables devices to simultaneously optimize transmission success rate and energy efficiency in a fully distributed manner. However, although UCB1-tuned based method is effective under stationary conditions, it suffers from slow adaptation in dynamic environments due to its strong reliance on historical observations. To address this limitation, we integrate the Schwarz Information Criterion (SIC) to our proposed method. SIC is adopted because it enables low-cost detection of changes in the communication environment, making it suitable for implementation on resource-constrained LoRa EDs. When a change is detected by SIC, the learning history of UCB1-tuned is reset, allowing rapid re-learning under the new conditions. Experimental results using real LoRa devices demonstrate that the proposed method achieves superior transmission success rate, energy efficiency, and adaptability compared with the conventional UCB1-tuned algorithm without SIC.</p></details> | 6 pages, 5 figures |
| **[Random state comonads encode cellular automata evaluation](https://arxiv.org/abs/2512.22067v1)** | 2025-12-26 | <details><summary>Show</summary><p>Cellular automata (CA) are quintessential ALife and ubiquitous in many studies of collective behaviour and emergence, from morphogenesis to social dynamics and even brain modelling. Recently, there has been an increased interest in formalising CA, theoretically through category theory and practically in terms of a functional programming paradigm. Unfortunately, these remain either in the realm of simple implementations lacking important practical features, or too abstract and conceptually inaccessible to be useful to the ALife community at large. In this paper, we present a brief and accessible introduction to a category-theoretical model of CA computation through a practical implementation in Haskell. We instantiate arrays as comonads with state and random generators, allowing stochastic behaviour not currently supported in other known implementations. We also emphasise the importance of functional implementations for complex systems: thanks to the Curry-Howard-Lambek isomorphism, functional programs facilitate a mapping between simulation, system rules or semantics, and categorical descriptions, which may advance our understanding and development of generalised theories of emergent behaviour. Using this implementation, we show case studies of four famous CA models: first Wolfram's CA in 1D, then Conway's game of life, Greenberg-Hasings excitable cells, and the stochastic Forest Fire model in 2D, and present directions for an extension to N dimensions. Finally, we suggest that the comonadic model can encode arbitrary topologies and propose future directions for a comonadic network.</p></details> | 5 pages, 5 figures |
| **[M2RU: Memristive Minion Recurrent Unit for On-Chip Continual Learning at the Edge](https://arxiv.org/abs/2512.17299v2)** | 2025-12-26 | <details><summary>Show</summary><p>Continual learning on edge platforms remains challenging because recurrent networks depend on energy-intensive training procedures and frequent data movement that are impractical for embedded deployments. This work introduces M2RU, a mixed-signal architecture that implements the minion recurrent unit for efficient temporal processing with on-chip continual learning. The architecture integrates weighted-bit streaming, which enables multi-bit digital inputs to be processed in crossbars without high-resolution conversion, and an experience replay mechanism that stabilizes learning under domain shifts. M2RU achieves 15 GOPS at 48.62 mW, corresponding to 312 GOPS per watt, and maintains accuracy within 5 percent of software baselines on sequential MNIST and CIFAR-10 tasks. Compared with a CMOS digital design, the accelerator provides 29X improvement in energy efficiency. Device-aware analysis shows an expected operational lifetime of 12.2 years under continual learning workloads. These results establish M2RU as a scalable and energy-efficient platform for real-time adaptation in edge-level temporal intelligence.</p></details> |  |
| **[Backdoor Attacks on Prompt-Driven Video Segmentation Foundation Models](https://arxiv.org/abs/2512.22046v1)** | 2025-12-26 | <details><summary>Show</summary><p>Prompt-driven Video Segmentation Foundation Models (VSFMs) such as SAM2 are increasingly deployed in applications like autonomous driving and digital pathology, raising concerns about backdoor threats. Surprisingly, we find that directly transferring classic backdoor attacks (e.g., BadNet) to VSFMs is almost ineffective, with ASR below 5\%. To understand this, we study encoder gradients and attention maps and observe that conventional training keeps gradients for clean and triggered samples largely aligned, while attention still focuses on the true object, preventing the encoder from learning a distinct trigger-related representation. To address this challenge, we propose BadVSFM, the first backdoor framework tailored to prompt-driven VSFMs. BadVSFM uses a two-stage strategy: (1) steer the image encoder so triggered frames map to a designated target embedding while clean frames remain aligned with a clean reference encoder; (2) train the mask decoder so that, across prompt types, triggered frame-prompt pairs produce a shared target mask, while clean outputs stay close to a reference decoder. Extensive experiments on two datasets and five VSFMs show that BadVSFM achieves strong, controllable backdoor effects under diverse triggers and prompts while preserving clean segmentation quality. Ablations over losses, stages, targets, trigger settings, and poisoning rates demonstrate robustness to reasonable hyperparameter changes and confirm the necessity of the two-stage design. Finally, gradient-conflict analysis and attention visualizations show that BadVSFM separates triggered and clean representations and shifts attention to trigger regions, while four representative defenses remain largely ineffective, revealing an underexplored vulnerability in current VSFMs.</p></details> |  |
| **[Direction Finding with Sparse Arrays Based on Variable Window Size Spatial Smoothing](https://arxiv.org/abs/2512.22024v1)** | 2025-12-26 | <details><summary>Show</summary><p>In this work, we introduce a variable window size (VWS) spatial smoothing framework that enhances coarray-based direction of arrival (DOA) estimation for sparse linear arrays. By compressing the smoothing aperture, the proposed VWS Coarray MUSIC (VWS-CA-MUSIC) and VWS Coarray root-MUSIC (VWS-CA-rMUSIC) algorithms replace part of the perturbed rank-one outer products in the smoothed coarray data with unperturbed low-rank additional terms, increasing the separation between signal and noise subspaces, while preserving the signal subspace span. We also derive the bounds that guarantees identifiability, by limiting the values that can be assumed by the compression parameter. Simulations with sparse geometries reveal significant performance improvements and complexity savings relative to the fixed-window coarray MUSIC method.</p></details> | 2 figures, 5 pages |
| **[Non-Resolution Reasoning (NRR): A Computational Framework for Contextual Identity and Ambiguity Preservation](https://arxiv.org/abs/2512.13478v5)** | 2025-12-26 | <details><summary>Show</summary><p>Current AI systems exhibit a fundamental limitation: they resolve ambiguity prematurely. This premature semantic collapse--collapsing multiple valid interpretations into single outputs--stems from classical identity assumptions in neural architectures. We propose Non-Resolution Reasoning (NRR), treating ambiguity retention as a valid reasoning mode. NRR introduces three principles: (1) Non-Identity ($A \neq A$)--the same symbol refers to different entities across contexts; (2) Approximate Identity ($A \approx A$)--entities share partial overlap without being identical; (3) Non-Resolution--conflicting interpretations coexist without forced convergence. We formalize these through Multi-Vector Embeddings, Non-Collapsing Attention, and Contextual Identity Tracking (CIT). Functional verification via Turn 1 Entropy measurement shows NRR-lite maintains high entropy ($H = 0.63$) at ambiguous turns while standard architectures collapse early ($H = 0.10$), demonstrating that NRR preserves interpretive flexibility until context arrives. The question is not whether AI should resolve ambiguity, but when, how, and under whose control.</p></details> | <details><summary>v5: M...</summary><p>v5: Major revision to Section 5. Replaced accuracy-based OOD evaluation with entropy-based functional verification (proof-of-concept). Clarified scope as architectural demonstration rather than comparative benchmark</p></details> |
| **[Research on a hybrid LSTM-CNN-Attention model for text-based web content classification](https://arxiv.org/abs/2512.18475v2)** | 2025-12-26 | <details><summary>Show</summary><p>This study presents a hybrid deep learning architecture that integrates LSTM, CNN, and an Attention mechanism to enhance the classification of web content based on text. Pretrained GloVe embeddings are used to represent words as dense vectors that preserve semantic similarity. The CNN layer extracts local n-gram patterns and lexical features, while the LSTM layer models long-range dependencies and sequential structure. The integrated Attention mechanism enables the model to focus selectively on the most informative parts of the input sequence. A 5-fold cross-validation setup was used to assess the robustness and generalizability of the proposed solution. Experimental results show that the hybrid LSTM-CNN-Attention model achieved outstanding performance, with an accuracy of 0.98, precision of 0.94, recall of 0.92, and F1-score of 0.93. These results surpass the performance of baseline models based solely on CNNs, LSTMs, or transformer-based classifiers such as BERT. The combination of neural network components enabled the model to effectively capture both fine-grained text structures and broader semantic context. Furthermore, the use of GloVe embeddings provided an efficient and effective representation of textual data, making the model suitable for integration into systems with real-time or near-real-time requirements. The proposed hybrid architecture demonstrates high effectiveness in text-based web content classification, particularly in tasks requiring both syntactic feature extraction and semantic interpretation. By combining presented mechanisms, the model addresses the limitations of individual architectures and achieves improved generalization. These findings support the broader use of hybrid deep learning approaches in NLP applications, especially where complex, unstructured textual data must be processed and classified with high reliability.</p></details> | <details><summary>10 pa...</summary><p>10 pages, 5 figures, 2 tables. Published by Radio Electronics Computer Science Control 2025</p></details> |
| **[Super-LIO: A Robust and Efficient LiDAR-Inertial Odometry System with a Compact Mapping Strategy](https://arxiv.org/abs/2509.05723v2)** | 2025-12-26 | <details><summary>Show</summary><p>LiDAR-Inertial Odometry (LIO) is a foundational technique for autonomous systems, yet its deployment on resource-constrained platforms remains challenging due to computational and memory limitations. We propose Super-LIO, a robust LIO system that demands both high performance and accuracy, ideal for applications such as aerial robots and mobile autonomous systems. At the core of Super-LIO is a compact octo-voxel-based map structure, termed OctVox, that limits each voxel to eight fused subvoxels, enabling strict point density control and incremental denoising during map updates. This design enables a simple yet efficient and accurate map structure, which can be easily integrated into existing LIO frameworks. Additionally, Super-LIO designs a heuristic-guided KNN strategy (HKNN) that accelerates the correspondence search by leveraging spatial locality, further reducing runtime overhead. We evaluated the proposed system using four publicly available datasets and several self-collected datasets, totaling more than 30 sequences. Extensive testing on both X86 and ARM platforms confirms that Super-LIO offers superior efficiency and robustness, while maintaining competitive accuracy. Super-LIO processes each frame approximately 73% faster than SOTA, while consuming less CPU resources. The system is fully open-source and plug-and-play compatible with a wide range of LiDAR sensors and platforms. The implementation is available at: https://github.com/Liansheng-Wang/Super-LIO.git</p></details> | 8 pages, 5 figures |

## Class Incremental
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[Schwarz Information Criterion Aided Multi-Armed Bandit for Decentralized Resource Allocation in Dynamic LoRa Networks](https://arxiv.org/abs/2512.22089v1)** | 2025-12-26 | <details><summary>Show</summary><p>This paper proposes a lightweight distributed learning method for transmission parameter selection in Long Range (LoRa) networks that can adapt to dynamic communication environments. In the proposed method, each LoRa End Device (ED) employs the Upper Confidence Bound (UCB)1-tuned algorithm to select transmission parameters including channel, transmission power, and bandwidth. The transmission parameters are selected based on the acknowledgment (ACK) feedback returned from the gateway after each transmission and the corresponding transmission energy consumption. Hence, it enables devices to simultaneously optimize transmission success rate and energy efficiency in a fully distributed manner. However, although UCB1-tuned based method is effective under stationary conditions, it suffers from slow adaptation in dynamic environments due to its strong reliance on historical observations. To address this limitation, we integrate the Schwarz Information Criterion (SIC) to our proposed method. SIC is adopted because it enables low-cost detection of changes in the communication environment, making it suitable for implementation on resource-constrained LoRa EDs. When a change is detected by SIC, the learning history of UCB1-tuned is reset, allowing rapid re-learning under the new conditions. Experimental results using real LoRa devices demonstrate that the proposed method achieves superior transmission success rate, energy efficiency, and adaptability compared with the conventional UCB1-tuned algorithm without SIC.</p></details> | 6 pages, 5 figures |
| **[Random state comonads encode cellular automata evaluation](https://arxiv.org/abs/2512.22067v1)** | 2025-12-26 | <details><summary>Show</summary><p>Cellular automata (CA) are quintessential ALife and ubiquitous in many studies of collective behaviour and emergence, from morphogenesis to social dynamics and even brain modelling. Recently, there has been an increased interest in formalising CA, theoretically through category theory and practically in terms of a functional programming paradigm. Unfortunately, these remain either in the realm of simple implementations lacking important practical features, or too abstract and conceptually inaccessible to be useful to the ALife community at large. In this paper, we present a brief and accessible introduction to a category-theoretical model of CA computation through a practical implementation in Haskell. We instantiate arrays as comonads with state and random generators, allowing stochastic behaviour not currently supported in other known implementations. We also emphasise the importance of functional implementations for complex systems: thanks to the Curry-Howard-Lambek isomorphism, functional programs facilitate a mapping between simulation, system rules or semantics, and categorical descriptions, which may advance our understanding and development of generalised theories of emergent behaviour. Using this implementation, we show case studies of four famous CA models: first Wolfram's CA in 1D, then Conway's game of life, Greenberg-Hasings excitable cells, and the stochastic Forest Fire model in 2D, and present directions for an extension to N dimensions. Finally, we suggest that the comonadic model can encode arbitrary topologies and propose future directions for a comonadic network.</p></details> | 5 pages, 5 figures |
| **[M2RU: Memristive Minion Recurrent Unit for On-Chip Continual Learning at the Edge](https://arxiv.org/abs/2512.17299v2)** | 2025-12-26 | <details><summary>Show</summary><p>Continual learning on edge platforms remains challenging because recurrent networks depend on energy-intensive training procedures and frequent data movement that are impractical for embedded deployments. This work introduces M2RU, a mixed-signal architecture that implements the minion recurrent unit for efficient temporal processing with on-chip continual learning. The architecture integrates weighted-bit streaming, which enables multi-bit digital inputs to be processed in crossbars without high-resolution conversion, and an experience replay mechanism that stabilizes learning under domain shifts. M2RU achieves 15 GOPS at 48.62 mW, corresponding to 312 GOPS per watt, and maintains accuracy within 5 percent of software baselines on sequential MNIST and CIFAR-10 tasks. Compared with a CMOS digital design, the accelerator provides 29X improvement in energy efficiency. Device-aware analysis shows an expected operational lifetime of 12.2 years under continual learning workloads. These results establish M2RU as a scalable and energy-efficient platform for real-time adaptation in edge-level temporal intelligence.</p></details> |  |
| **[Backdoor Attacks on Prompt-Driven Video Segmentation Foundation Models](https://arxiv.org/abs/2512.22046v1)** | 2025-12-26 | <details><summary>Show</summary><p>Prompt-driven Video Segmentation Foundation Models (VSFMs) such as SAM2 are increasingly deployed in applications like autonomous driving and digital pathology, raising concerns about backdoor threats. Surprisingly, we find that directly transferring classic backdoor attacks (e.g., BadNet) to VSFMs is almost ineffective, with ASR below 5\%. To understand this, we study encoder gradients and attention maps and observe that conventional training keeps gradients for clean and triggered samples largely aligned, while attention still focuses on the true object, preventing the encoder from learning a distinct trigger-related representation. To address this challenge, we propose BadVSFM, the first backdoor framework tailored to prompt-driven VSFMs. BadVSFM uses a two-stage strategy: (1) steer the image encoder so triggered frames map to a designated target embedding while clean frames remain aligned with a clean reference encoder; (2) train the mask decoder so that, across prompt types, triggered frame-prompt pairs produce a shared target mask, while clean outputs stay close to a reference decoder. Extensive experiments on two datasets and five VSFMs show that BadVSFM achieves strong, controllable backdoor effects under diverse triggers and prompts while preserving clean segmentation quality. Ablations over losses, stages, targets, trigger settings, and poisoning rates demonstrate robustness to reasonable hyperparameter changes and confirm the necessity of the two-stage design. Finally, gradient-conflict analysis and attention visualizations show that BadVSFM separates triggered and clean representations and shifts attention to trigger regions, while four representative defenses remain largely ineffective, revealing an underexplored vulnerability in current VSFMs.</p></details> |  |
| **[Direction Finding with Sparse Arrays Based on Variable Window Size Spatial Smoothing](https://arxiv.org/abs/2512.22024v1)** | 2025-12-26 | <details><summary>Show</summary><p>In this work, we introduce a variable window size (VWS) spatial smoothing framework that enhances coarray-based direction of arrival (DOA) estimation for sparse linear arrays. By compressing the smoothing aperture, the proposed VWS Coarray MUSIC (VWS-CA-MUSIC) and VWS Coarray root-MUSIC (VWS-CA-rMUSIC) algorithms replace part of the perturbed rank-one outer products in the smoothed coarray data with unperturbed low-rank additional terms, increasing the separation between signal and noise subspaces, while preserving the signal subspace span. We also derive the bounds that guarantees identifiability, by limiting the values that can be assumed by the compression parameter. Simulations with sparse geometries reveal significant performance improvements and complexity savings relative to the fixed-window coarray MUSIC method.</p></details> | 2 figures, 5 pages |
| **[Non-Resolution Reasoning (NRR): A Computational Framework for Contextual Identity and Ambiguity Preservation](https://arxiv.org/abs/2512.13478v5)** | 2025-12-26 | <details><summary>Show</summary><p>Current AI systems exhibit a fundamental limitation: they resolve ambiguity prematurely. This premature semantic collapse--collapsing multiple valid interpretations into single outputs--stems from classical identity assumptions in neural architectures. We propose Non-Resolution Reasoning (NRR), treating ambiguity retention as a valid reasoning mode. NRR introduces three principles: (1) Non-Identity ($A \neq A$)--the same symbol refers to different entities across contexts; (2) Approximate Identity ($A \approx A$)--entities share partial overlap without being identical; (3) Non-Resolution--conflicting interpretations coexist without forced convergence. We formalize these through Multi-Vector Embeddings, Non-Collapsing Attention, and Contextual Identity Tracking (CIT). Functional verification via Turn 1 Entropy measurement shows NRR-lite maintains high entropy ($H = 0.63$) at ambiguous turns while standard architectures collapse early ($H = 0.10$), demonstrating that NRR preserves interpretive flexibility until context arrives. The question is not whether AI should resolve ambiguity, but when, how, and under whose control.</p></details> | <details><summary>v5: M...</summary><p>v5: Major revision to Section 5. Replaced accuracy-based OOD evaluation with entropy-based functional verification (proof-of-concept). Clarified scope as architectural demonstration rather than comparative benchmark</p></details> |
| **[Research on a hybrid LSTM-CNN-Attention model for text-based web content classification](https://arxiv.org/abs/2512.18475v2)** | 2025-12-26 | <details><summary>Show</summary><p>This study presents a hybrid deep learning architecture that integrates LSTM, CNN, and an Attention mechanism to enhance the classification of web content based on text. Pretrained GloVe embeddings are used to represent words as dense vectors that preserve semantic similarity. The CNN layer extracts local n-gram patterns and lexical features, while the LSTM layer models long-range dependencies and sequential structure. The integrated Attention mechanism enables the model to focus selectively on the most informative parts of the input sequence. A 5-fold cross-validation setup was used to assess the robustness and generalizability of the proposed solution. Experimental results show that the hybrid LSTM-CNN-Attention model achieved outstanding performance, with an accuracy of 0.98, precision of 0.94, recall of 0.92, and F1-score of 0.93. These results surpass the performance of baseline models based solely on CNNs, LSTMs, or transformer-based classifiers such as BERT. The combination of neural network components enabled the model to effectively capture both fine-grained text structures and broader semantic context. Furthermore, the use of GloVe embeddings provided an efficient and effective representation of textual data, making the model suitable for integration into systems with real-time or near-real-time requirements. The proposed hybrid architecture demonstrates high effectiveness in text-based web content classification, particularly in tasks requiring both syntactic feature extraction and semantic interpretation. By combining presented mechanisms, the model addresses the limitations of individual architectures and achieves improved generalization. These findings support the broader use of hybrid deep learning approaches in NLP applications, especially where complex, unstructured textual data must be processed and classified with high reliability.</p></details> | <details><summary>10 pa...</summary><p>10 pages, 5 figures, 2 tables. Published by Radio Electronics Computer Science Control 2025</p></details> |
| **[Super-LIO: A Robust and Efficient LiDAR-Inertial Odometry System with a Compact Mapping Strategy](https://arxiv.org/abs/2509.05723v2)** | 2025-12-26 | <details><summary>Show</summary><p>LiDAR-Inertial Odometry (LIO) is a foundational technique for autonomous systems, yet its deployment on resource-constrained platforms remains challenging due to computational and memory limitations. We propose Super-LIO, a robust LIO system that demands both high performance and accuracy, ideal for applications such as aerial robots and mobile autonomous systems. At the core of Super-LIO is a compact octo-voxel-based map structure, termed OctVox, that limits each voxel to eight fused subvoxels, enabling strict point density control and incremental denoising during map updates. This design enables a simple yet efficient and accurate map structure, which can be easily integrated into existing LIO frameworks. Additionally, Super-LIO designs a heuristic-guided KNN strategy (HKNN) that accelerates the correspondence search by leveraging spatial locality, further reducing runtime overhead. We evaluated the proposed system using four publicly available datasets and several self-collected datasets, totaling more than 30 sequences. Extensive testing on both X86 and ARM platforms confirms that Super-LIO offers superior efficiency and robustness, while maintaining competitive accuracy. Super-LIO processes each frame approximately 73% faster than SOTA, while consuming less CPU resources. The system is fully open-source and plug-and-play compatible with a wide range of LiDAR sensors and platforms. The implementation is available at: https://github.com/Liansheng-Wang/Super-LIO.git</p></details> | 8 pages, 5 figures |

